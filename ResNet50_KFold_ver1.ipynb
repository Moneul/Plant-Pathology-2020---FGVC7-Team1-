{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git remote add origin https://github.com/Moneul/Plant-Pathology-2020---FGVC7-Team6-.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "\n",
    "git add .\n",
    "git commit -m 'AISW_Plant Pathology 2020 - FGVC7 Team6 김민섭 정지훈'\n",
    "git push origin Moneul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하는 라이브러리\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 디렉토리의 첫 번째 파일명에서 확장자를 제외한 부분을 추출하여 변수 name에 저장\n",
    "name = os.listdir('./')[0].split('.')[0]\n",
    "# print(name) -> ResNet50_KFold_ver1\n",
    "\n",
    "# 데이터 경로 설정\n",
    "path = '../data/plant-pathology-2020-fgvc7/'\n",
    "\n",
    "# train과 test 데이터 로드\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "\n",
    "# 파일명에 확장자 '.jpg'를 추가하여 train과 test 데이터의 'image_id' 열 값 수정\n",
    "train['image_id'] = train['image_id'] + '.jpg'\n",
    "test['image_id'] = test['image_id'] + '.jpg'\n",
    "\n",
    "\n",
    "# 훈련 데이터의 라벨값을 numpy 배열로 변환\n",
    "train_labels = np.float32(train.loc[:, 'healthy':'scab'].values)\n",
    "\n",
    "# K-fold 교차 검증을 통해 데이터를 훈련 세트와 검증 세트로 분할\n",
    "# n_split : 몇 개의 폴드로 나눌지 / shuffle : 데이터를 나누기 전에 섞을지 여부를 결정\n",
    "K=5\n",
    "kfold = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "fold = 1 # 폴드 시작 수\n",
    "\n",
    "# kfold.split(train) : train을 K개의 폴드로 나눈 후 각 폴드에 학습용 검증용 인덱스 반환\n",
    "# for문을 통해 각 폴드마다 반복\n",
    "for train_indices, val_indices in kfold.split(train):\n",
    "    print(f\"Training on fold: {fold}\")\n",
    "    train_fold = train.iloc[train_indices] # 폴드에서 학습으로 사용될 데이터\n",
    "    val_fold = train.iloc[val_indices] # 폴드에서 검증으로 사용될 데이터\n",
    "\n",
    "\n",
    "    # open-cv2로 이미지를 불러오기 및 전처리\n",
    "    # img = []\n",
    "    # filename = train.image_id\n",
    "    # for file in filename:\n",
    "    #     image = cv2.imread(path + \"images/\" + file)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #     res = cv2.resize(image, (256, 256))\n",
    "    #     img.append(res)\n",
    "    # img = np.array(img)\n",
    "    \n",
    "    \n",
    "    # 데이터 증강(Data Augmentation)을 위한 ImageDataGenerator 생성\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,       # 수평으로 뒤집기\n",
    "        vertical_flip=True,         # 수직으로 뒤집기\n",
    "        rotation_range=45,          # 범위내 무작위로 회전\n",
    "        width_shift_range=0.45,     # 범위내 무작위 가로 이동\n",
    "        height_shift_range=0.45,    # 범위내 무작위 세로 이동\n",
    "        zoom_range=.2,              # 범위내 무작위 확대 및 축소 \n",
    "        fill_mode='nearest',        # 이미지 변형시 빈 공간을 채우는 방법\n",
    "        rescale=1 / 255,            # 정규화 np.array와 동일\n",
    "        brightness_range=[0.5, 1.5] # 범위내 무작위 밝기 조절\n",
    "    )\n",
    "\n",
    "    # train_generator 생성\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_fold,                 # 학습용 이미지 파일의 정보\n",
    "        directory=path + 'images/', # 이미지를 불러오기위한 경로 지정\n",
    "        target_size=(256, 256),     # 사용할 이미지 크기 지정\n",
    "        x_col=\"image_id\",           # 이미지 \n",
    "        y_col=['healthy', 'multiple_diseases', 'rust', 'scab'], # 레이블 값\n",
    "        class_mode='raw',           # 레이블 형식 지정\n",
    "        shuffle=False,                  \n",
    "        batch_size=32               # 각 배치에 포함될 이미지 수\n",
    "    )\n",
    "\n",
    "    # val_generator 생성\n",
    "    val_generator = train_datagen.flow_from_dataframe(\n",
    "        val_fold,\n",
    "        directory=path + 'images/',\n",
    "        target_size=(256, 256),\n",
    "        x_col=\"image_id\",\n",
    "        y_col=['healthy', 'multiple_diseases', 'rust', 'scab'],\n",
    "        class_mode='raw',\n",
    "        shuffle=False,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    # 모델 구성\n",
    "    model_finetuned = ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "    x = model_finetuned.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    predictions = Dense(4, activation=\"softmax\")(x)\n",
    "    model_finetuned = Model(inputs=model_finetuned.input, outputs=predictions)\n",
    "    model_finetuned.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_finetuned.summary()\n",
    "\n",
    "    # Early Stopping 및 Model Checkpoint 등의 콜백 함수 설정\n",
    "    # val_loss를 모니터링하며 15회(patience)동안 개선되지않으면 조기종료\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", verbose=1, patience=15)\n",
    "\n",
    "    # 최적의 모델 저장장\n",
    "    modelcheckpointer = ModelCheckpoint(\n",
    "        f'./{name}_fold{fold}.hdf5',\n",
    "        monitor='val_loss',     # 모니터링 대상\n",
    "        mode='min',             # 모니터링 대상의 성능 지표 지정\n",
    "        verbose=1,\n",
    "        save_best_only=True     # 가장 좋은 성능을 보이는 모델만 저장\n",
    "    )\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model_finetuned.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        batch_size=8,\n",
    "        validation_data=val_generator, \n",
    "        validation_batch_size=8,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        callbacks=[modelcheckpointer, ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.4, patience=7, min_lr=0.0000001, verbose=1)]\n",
    "        # val_loss를 모니터링하며 지정횟수(patience)동안 개선 되지않으면 학습률 0.4(factor)배 감소\n",
    "        # 학습률 최소값을 0.0000001(min_lr)로 지정해 학습률이 이 값보다 작아지지 않도록 설정\n",
    "    )\n",
    "\n",
    "    # 학습 과정의 손실값 및 정확도 그래프 출력\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    y_vloss = history.history['val_loss']\n",
    "    y_loss = history.history['loss']\n",
    "    y_acc = history.history['accuracy']\n",
    "    y_vacc = history.history['val_accuracy']\n",
    "    best_val_accuracy = np.array(y_vacc).max()\n",
    "    x_len = np.arange(len(y_loss))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x_len, y_vloss, marker='.', c='red', label='val_loss')\n",
    "    plt.plot(x_len, y_loss, marker='.', c='blue', label='train_loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_len, y_vacc, marker='.', c='orange', label='val_accuracy')\n",
    "    plt.plot(x_len, y_acc, marker='.', c='green', label='train_accuracy')\n",
    "    plt.title(f'best train_accuracy : {best_val_accuracy}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.savefig(f'../그래프/{name}_fold{fold}_{best_val_accuracy}.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Test 데이터를 예측하기 위한 이미지 불러오기\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    directory=path + 'images/',\n",
    "    target_size=(256, 256),\n",
    "    x_col=\"image_id\",\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# submission 파일 로드\n",
    "SUB_PATH = path + \"sample_submission.csv\"\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "\n",
    "# K-fold로 생성된 모델들의 예측 결과 합산\n",
    "probs_RESNET = np.zeros((test.shape[0], 4))\n",
    "fold = 5\n",
    "for i in range(1, fold + 1):\n",
    "    model_finetuned.load_weights(f'./{name}_fold{i}.hdf5')\n",
    "    # 각 폴드로 생성된 모델로 예측한 값을 저장\n",
    "    fold_probs = model_finetuned.predict(test_generator, verbose=1)\n",
    "    probs_RESNET += fold_probs # 각 폴드별 예측값 누적\n",
    "probs_RESNET /= fold # 평균값 구하기\n",
    "\n",
    "# submission 파일에 예측 결과 저장\n",
    "sub.loc[:, 'healthy':] = probs_RESNET\n",
    "sub.to_csv(f'./{name}_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50_KFold_ver1\n",
      "Training on fold: 1\n",
      "Found 1456 validated image filenames.\n",
      "Found 365 validated image filenames.\n",
      "Found 1821 validated image filenames.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            260         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,858,500\n",
      "Trainable params: 23,805,380\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.9912 - accuracy: 0.6676\n",
      "Epoch 1: val_loss improved from inf to 2.09051, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 41s 713ms/step - loss: 0.9912 - accuracy: 0.6676 - val_loss: 2.0905 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6502 - accuracy: 0.8022\n",
      "Epoch 2: val_loss improved from 2.09051 to 1.42380, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 33s 701ms/step - loss: 0.6502 - accuracy: 0.8022 - val_loss: 1.4238 - val_accuracy: 0.3479 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8379\n",
      "Epoch 3: val_loss did not improve from 1.42380\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.5051 - accuracy: 0.8379 - val_loss: 1.5266 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8516\n",
      "Epoch 4: val_loss did not improve from 1.42380\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.4849 - accuracy: 0.8516 - val_loss: 1.6480 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.8709\n",
      "Epoch 5: val_loss improved from 1.42380 to 1.34806, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.4541 - accuracy: 0.8709 - val_loss: 1.3481 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8853\n",
      "Epoch 6: val_loss improved from 1.34806 to 1.33885, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.3980 - accuracy: 0.8853 - val_loss: 1.3388 - val_accuracy: 0.3479 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8805\n",
      "Epoch 7: val_loss improved from 1.33885 to 1.27881, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 34s 730ms/step - loss: 0.4190 - accuracy: 0.8805 - val_loss: 1.2788 - val_accuracy: 0.3479 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8791\n",
      "Epoch 8: val_loss did not improve from 1.27881\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.3859 - accuracy: 0.8791 - val_loss: 1.4798 - val_accuracy: 0.3288 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8894\n",
      "Epoch 9: val_loss did not improve from 1.27881\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.3682 - accuracy: 0.8894 - val_loss: 1.3089 - val_accuracy: 0.3288 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8887\n",
      "Epoch 10: val_loss improved from 1.27881 to 1.26804, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.3857 - accuracy: 0.8887 - val_loss: 1.2680 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8935\n",
      "Epoch 11: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.3468 - accuracy: 0.8935 - val_loss: 1.4068 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.8874\n",
      "Epoch 12: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.3696 - accuracy: 0.8874 - val_loss: 2.0371 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8922\n",
      "Epoch 13: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.3386 - accuracy: 0.8922 - val_loss: 1.3266 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.9100\n",
      "Epoch 14: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.3157 - accuracy: 0.9100 - val_loss: 1.3235 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.8970\n",
      "Epoch 15: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.3102 - accuracy: 0.8970 - val_loss: 1.6088 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.8984\n",
      "Epoch 16: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.3157 - accuracy: 0.8984 - val_loss: 1.4921 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.9052\n",
      "Epoch 17: val_loss did not improve from 1.26804\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.2969 - accuracy: 0.9052 - val_loss: 2.7552 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.9210\n",
      "Epoch 18: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.2728 - accuracy: 0.9210 - val_loss: 2.0598 - val_accuracy: 0.3726 - lr: 4.0000e-04\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9148\n",
      "Epoch 19: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.2751 - accuracy: 0.9148 - val_loss: 1.8503 - val_accuracy: 0.4877 - lr: 4.0000e-04\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.9148\n",
      "Epoch 20: val_loss did not improve from 1.26804\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.2630 - accuracy: 0.9148 - val_loss: 1.6835 - val_accuracy: 0.5068 - lr: 4.0000e-04\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9293\n",
      "Epoch 21: val_loss improved from 1.26804 to 1.26280, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.2353 - accuracy: 0.9293 - val_loss: 1.2628 - val_accuracy: 0.5507 - lr: 4.0000e-04\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.9210\n",
      "Epoch 22: val_loss improved from 1.26280 to 0.91540, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.2462 - accuracy: 0.9210 - val_loss: 0.9154 - val_accuracy: 0.7342 - lr: 4.0000e-04\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.9183\n",
      "Epoch 23: val_loss improved from 0.91540 to 0.64316, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.2427 - accuracy: 0.9183 - val_loss: 0.6432 - val_accuracy: 0.8137 - lr: 4.0000e-04\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.9183\n",
      "Epoch 24: val_loss improved from 0.64316 to 0.48644, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.2540 - accuracy: 0.9183 - val_loss: 0.4864 - val_accuracy: 0.8356 - lr: 4.0000e-04\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9306\n",
      "Epoch 25: val_loss did not improve from 0.48644\n",
      "46/46 [==============================] - 31s 682ms/step - loss: 0.2172 - accuracy: 0.9306 - val_loss: 0.6884 - val_accuracy: 0.8411 - lr: 4.0000e-04\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9210\n",
      "Epoch 26: val_loss did not improve from 0.48644\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.2373 - accuracy: 0.9210 - val_loss: 0.4966 - val_accuracy: 0.8603 - lr: 4.0000e-04\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9265\n",
      "Epoch 27: val_loss improved from 0.48644 to 0.35361, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 703ms/step - loss: 0.2308 - accuracy: 0.9265 - val_loss: 0.3536 - val_accuracy: 0.9014 - lr: 4.0000e-04\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9238\n",
      "Epoch 28: val_loss did not improve from 0.35361\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.2196 - accuracy: 0.9238 - val_loss: 0.4823 - val_accuracy: 0.8164 - lr: 4.0000e-04\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9258\n",
      "Epoch 29: val_loss did not improve from 0.35361\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.2382 - accuracy: 0.9258 - val_loss: 0.5516 - val_accuracy: 0.8274 - lr: 4.0000e-04\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9361\n",
      "Epoch 30: val_loss did not improve from 0.35361\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.2070 - accuracy: 0.9361 - val_loss: 0.3982 - val_accuracy: 0.9014 - lr: 4.0000e-04\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9251\n",
      "Epoch 31: val_loss improved from 0.35361 to 0.28986, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 698ms/step - loss: 0.2298 - accuracy: 0.9251 - val_loss: 0.2899 - val_accuracy: 0.9123 - lr: 4.0000e-04\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9286\n",
      "Epoch 32: val_loss did not improve from 0.28986\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.2357 - accuracy: 0.9286 - val_loss: 0.3199 - val_accuracy: 0.9096 - lr: 4.0000e-04\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9279\n",
      "Epoch 33: val_loss did not improve from 0.28986\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.2155 - accuracy: 0.9279 - val_loss: 0.3942 - val_accuracy: 0.8849 - lr: 4.0000e-04\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9375\n",
      "Epoch 34: val_loss improved from 0.28986 to 0.23976, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1847 - accuracy: 0.9375 - val_loss: 0.2398 - val_accuracy: 0.9425 - lr: 4.0000e-04\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9375\n",
      "Epoch 35: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.2111 - accuracy: 0.9375 - val_loss: 0.3517 - val_accuracy: 0.9014 - lr: 4.0000e-04\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9196\n",
      "Epoch 36: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.2349 - accuracy: 0.9196 - val_loss: 0.3390 - val_accuracy: 0.8932 - lr: 4.0000e-04\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9375\n",
      "Epoch 37: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.1985 - accuracy: 0.9375 - val_loss: 0.3909 - val_accuracy: 0.8932 - lr: 4.0000e-04\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9279\n",
      "Epoch 38: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.2294 - accuracy: 0.9279 - val_loss: 0.3522 - val_accuracy: 0.8658 - lr: 4.0000e-04\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9245\n",
      "Epoch 39: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.2137 - accuracy: 0.9245 - val_loss: 0.5000 - val_accuracy: 0.8192 - lr: 4.0000e-04\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9375\n",
      "Epoch 40: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1871 - accuracy: 0.9375 - val_loss: 0.4316 - val_accuracy: 0.8658 - lr: 4.0000e-04\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9451\n",
      "Epoch 41: val_loss did not improve from 0.23976\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1634 - accuracy: 0.9451 - val_loss: 0.3715 - val_accuracy: 0.8822 - lr: 4.0000e-04\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9492\n",
      "Epoch 42: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1675 - accuracy: 0.9492 - val_loss: 0.2594 - val_accuracy: 0.9151 - lr: 1.6000e-04\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9396\n",
      "Epoch 43: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.1726 - accuracy: 0.9396 - val_loss: 0.2732 - val_accuracy: 0.9260 - lr: 1.6000e-04\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9471\n",
      "Epoch 44: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1602 - accuracy: 0.9471 - val_loss: 0.2421 - val_accuracy: 0.9315 - lr: 1.6000e-04\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9492\n",
      "Epoch 45: val_loss did not improve from 0.23976\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 0.3169 - val_accuracy: 0.9123 - lr: 1.6000e-04\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9451\n",
      "Epoch 46: val_loss improved from 0.23976 to 0.19871, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 0.1682 - accuracy: 0.9451 - val_loss: 0.1987 - val_accuracy: 0.9315 - lr: 1.6000e-04\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9505\n",
      "Epoch 47: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1587 - accuracy: 0.9505 - val_loss: 0.2525 - val_accuracy: 0.9260 - lr: 1.6000e-04\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9526\n",
      "Epoch 48: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1572 - accuracy: 0.9526 - val_loss: 0.2491 - val_accuracy: 0.9425 - lr: 1.6000e-04\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9567\n",
      "Epoch 49: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1332 - accuracy: 0.9567 - val_loss: 0.2723 - val_accuracy: 0.9342 - lr: 1.6000e-04\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9423\n",
      "Epoch 50: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.1728 - accuracy: 0.9423 - val_loss: 0.3968 - val_accuracy: 0.9096 - lr: 1.6000e-04\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9478\n",
      "Epoch 51: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.1619 - accuracy: 0.9478 - val_loss: 0.3715 - val_accuracy: 0.9342 - lr: 1.6000e-04\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9464\n",
      "Epoch 52: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1473 - accuracy: 0.9464 - val_loss: 0.2941 - val_accuracy: 0.8959 - lr: 1.6000e-04\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9560\n",
      "Epoch 53: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.1312 - accuracy: 0.9560 - val_loss: 0.2544 - val_accuracy: 0.9342 - lr: 1.6000e-04\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9567\n",
      "Epoch 54: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 34s 735ms/step - loss: 0.1353 - accuracy: 0.9567 - val_loss: 0.2187 - val_accuracy: 0.9233 - lr: 6.4000e-05\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9547\n",
      "Epoch 55: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 0.1295 - accuracy: 0.9547 - val_loss: 0.2472 - val_accuracy: 0.9342 - lr: 6.4000e-05\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9629\n",
      "Epoch 56: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 698ms/step - loss: 0.1166 - accuracy: 0.9629 - val_loss: 0.2211 - val_accuracy: 0.9452 - lr: 6.4000e-05\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9622\n",
      "Epoch 57: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.1191 - accuracy: 0.9622 - val_loss: 0.2291 - val_accuracy: 0.9479 - lr: 6.4000e-05\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9595\n",
      "Epoch 58: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1249 - accuracy: 0.9595 - val_loss: 0.2068 - val_accuracy: 0.9397 - lr: 6.4000e-05\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9574\n",
      "Epoch 59: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 723ms/step - loss: 0.1315 - accuracy: 0.9574 - val_loss: 0.2057 - val_accuracy: 0.9425 - lr: 6.4000e-05\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9609\n",
      "Epoch 60: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "46/46 [==============================] - 34s 727ms/step - loss: 0.1311 - accuracy: 0.9609 - val_loss: 0.2465 - val_accuracy: 0.9205 - lr: 6.4000e-05\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9615\n",
      "Epoch 61: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1130 - accuracy: 0.9615 - val_loss: 0.1998 - val_accuracy: 0.9342 - lr: 2.5600e-05\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9657\n",
      "Epoch 62: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1099 - accuracy: 0.9657 - val_loss: 0.3160 - val_accuracy: 0.9315 - lr: 2.5600e-05\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9636\n",
      "Epoch 63: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1220 - accuracy: 0.9636 - val_loss: 0.2154 - val_accuracy: 0.9479 - lr: 2.5600e-05\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9663\n",
      "Epoch 64: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.1102 - accuracy: 0.9663 - val_loss: 0.2646 - val_accuracy: 0.9452 - lr: 2.5600e-05\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9691\n",
      "Epoch 65: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 0.1073 - accuracy: 0.9691 - val_loss: 0.2105 - val_accuracy: 0.9479 - lr: 2.5600e-05\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9712\n",
      "Epoch 66: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 723ms/step - loss: 0.0963 - accuracy: 0.9712 - val_loss: 0.2325 - val_accuracy: 0.9397 - lr: 2.5600e-05\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9650\n",
      "Epoch 67: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1119 - accuracy: 0.9650 - val_loss: 0.2953 - val_accuracy: 0.9397 - lr: 2.5600e-05\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9609\n",
      "Epoch 68: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1281 - accuracy: 0.9609 - val_loss: 0.2478 - val_accuracy: 0.9507 - lr: 1.0240e-05\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9670\n",
      "Epoch 69: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1090 - accuracy: 0.9670 - val_loss: 0.2772 - val_accuracy: 0.9315 - lr: 1.0240e-05\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9615\n",
      "Epoch 70: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1202 - accuracy: 0.9615 - val_loss: 0.2162 - val_accuracy: 0.9370 - lr: 1.0240e-05\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9615\n",
      "Epoch 71: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.1182 - accuracy: 0.9615 - val_loss: 0.2380 - val_accuracy: 0.9452 - lr: 1.0240e-05\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9650\n",
      "Epoch 72: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1110 - accuracy: 0.9650 - val_loss: 0.2212 - val_accuracy: 0.9452 - lr: 1.0240e-05\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9609\n",
      "Epoch 73: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 0.2312 - val_accuracy: 0.9425 - lr: 1.0240e-05\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9663\n",
      "Epoch 74: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 0.1014 - accuracy: 0.9663 - val_loss: 0.2298 - val_accuracy: 0.9315 - lr: 1.0240e-05\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9657\n",
      "Epoch 75: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.1101 - accuracy: 0.9657 - val_loss: 0.2985 - val_accuracy: 0.9370 - lr: 4.0960e-06\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9670\n",
      "Epoch 76: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.1074 - accuracy: 0.9670 - val_loss: 0.2352 - val_accuracy: 0.9452 - lr: 4.0960e-06\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9650\n",
      "Epoch 77: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 34s 731ms/step - loss: 0.1124 - accuracy: 0.9650 - val_loss: 0.2688 - val_accuracy: 0.9425 - lr: 4.0960e-06\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9643\n",
      "Epoch 78: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1082 - accuracy: 0.9643 - val_loss: 0.2566 - val_accuracy: 0.9507 - lr: 4.0960e-06\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9622\n",
      "Epoch 79: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 35s 749ms/step - loss: 0.1219 - accuracy: 0.9622 - val_loss: 0.2693 - val_accuracy: 0.9123 - lr: 4.0960e-06\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9698\n",
      "Epoch 80: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 34s 736ms/step - loss: 0.1032 - accuracy: 0.9698 - val_loss: 0.2069 - val_accuracy: 0.9425 - lr: 4.0960e-06\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9643\n",
      "Epoch 81: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1068 - accuracy: 0.9643 - val_loss: 0.2620 - val_accuracy: 0.9315 - lr: 4.0960e-06\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9732\n",
      "Epoch 82: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.0858 - accuracy: 0.9732 - val_loss: 0.2826 - val_accuracy: 0.9397 - lr: 1.6384e-06\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9650\n",
      "Epoch 83: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.2508 - val_accuracy: 0.9507 - lr: 1.6384e-06\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9670\n",
      "Epoch 84: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1040 - accuracy: 0.9670 - val_loss: 0.2198 - val_accuracy: 0.9452 - lr: 1.6384e-06\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9705\n",
      "Epoch 85: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1074 - accuracy: 0.9705 - val_loss: 0.2443 - val_accuracy: 0.9315 - lr: 1.6384e-06\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9615\n",
      "Epoch 86: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1152 - accuracy: 0.9615 - val_loss: 0.2525 - val_accuracy: 0.9370 - lr: 1.6384e-06\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9540\n",
      "Epoch 87: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1318 - accuracy: 0.9540 - val_loss: 0.2781 - val_accuracy: 0.9425 - lr: 1.6384e-06\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9663\n",
      "Epoch 88: val_loss did not improve from 0.19871\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1061 - accuracy: 0.9663 - val_loss: 0.2708 - val_accuracy: 0.9452 - lr: 1.6384e-06\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9684\n",
      "Epoch 89: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.1067 - accuracy: 0.9684 - val_loss: 0.2515 - val_accuracy: 0.9479 - lr: 6.5536e-07\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9615\n",
      "Epoch 90: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1161 - accuracy: 0.9615 - val_loss: 0.2357 - val_accuracy: 0.9397 - lr: 6.5536e-07\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9602\n",
      "Epoch 91: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1137 - accuracy: 0.9602 - val_loss: 0.2581 - val_accuracy: 0.9233 - lr: 6.5536e-07\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9650\n",
      "Epoch 92: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1047 - accuracy: 0.9650 - val_loss: 0.2210 - val_accuracy: 0.9479 - lr: 6.5536e-07\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9670\n",
      "Epoch 93: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1064 - accuracy: 0.9670 - val_loss: 0.2133 - val_accuracy: 0.9562 - lr: 6.5536e-07\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9684\n",
      "Epoch 94: val_loss did not improve from 0.19871\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.0987 - accuracy: 0.9684 - val_loss: 0.2991 - val_accuracy: 0.9342 - lr: 6.5536e-07\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9657\n",
      "Epoch 95: val_loss improved from 0.19871 to 0.19280, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 0.1928 - val_accuracy: 0.9507 - lr: 6.5536e-07\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9691\n",
      "Epoch 96: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1000 - accuracy: 0.9691 - val_loss: 0.2653 - val_accuracy: 0.9452 - lr: 6.5536e-07\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9698\n",
      "Epoch 97: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.1001 - accuracy: 0.9698 - val_loss: 0.2623 - val_accuracy: 0.9479 - lr: 6.5536e-07\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9615\n",
      "Epoch 98: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 665ms/step - loss: 0.1238 - accuracy: 0.9615 - val_loss: 0.2570 - val_accuracy: 0.9479 - lr: 6.5536e-07\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9581\n",
      "Epoch 99: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.1162 - accuracy: 0.9581 - val_loss: 0.2321 - val_accuracy: 0.9479 - lr: 6.5536e-07\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9657\n",
      "Epoch 100: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.1078 - accuracy: 0.9657 - val_loss: 0.2224 - val_accuracy: 0.9260 - lr: 6.5536e-07\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9602\n",
      "Epoch 101: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 661ms/step - loss: 0.1197 - accuracy: 0.9602 - val_loss: 0.2395 - val_accuracy: 0.9452 - lr: 6.5536e-07\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9622\n",
      "Epoch 102: val_loss did not improve from 0.19280\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1101 - accuracy: 0.9622 - val_loss: 0.2877 - val_accuracy: 0.9315 - lr: 6.5536e-07\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9712\n",
      "Epoch 103: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.0983 - accuracy: 0.9712 - val_loss: 0.2415 - val_accuracy: 0.9479 - lr: 2.6214e-07\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9650\n",
      "Epoch 104: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.1181 - accuracy: 0.9650 - val_loss: 0.2754 - val_accuracy: 0.9425 - lr: 2.6214e-07\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9712\n",
      "Epoch 105: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.0942 - accuracy: 0.9712 - val_loss: 0.2523 - val_accuracy: 0.9233 - lr: 2.6214e-07\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9650\n",
      "Epoch 106: val_loss did not improve from 0.19280\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.1150 - accuracy: 0.9650 - val_loss: 0.2660 - val_accuracy: 0.9425 - lr: 2.6214e-07\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9718\n",
      "Epoch 107: val_loss improved from 0.19280 to 0.18875, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0954 - accuracy: 0.9718 - val_loss: 0.1887 - val_accuracy: 0.9507 - lr: 2.6214e-07\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9691\n",
      "Epoch 108: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.1016 - accuracy: 0.9691 - val_loss: 0.2535 - val_accuracy: 0.9315 - lr: 2.6214e-07\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9718\n",
      "Epoch 109: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0921 - accuracy: 0.9718 - val_loss: 0.2929 - val_accuracy: 0.9342 - lr: 2.6214e-07\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9643\n",
      "Epoch 110: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1143 - accuracy: 0.9643 - val_loss: 0.2322 - val_accuracy: 0.9288 - lr: 2.6214e-07\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9650\n",
      "Epoch 111: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1134 - accuracy: 0.9650 - val_loss: 0.2555 - val_accuracy: 0.9425 - lr: 2.6214e-07\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9677\n",
      "Epoch 112: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0975 - accuracy: 0.9677 - val_loss: 0.2495 - val_accuracy: 0.9397 - lr: 2.6214e-07\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9609\n",
      "Epoch 113: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1159 - accuracy: 0.9609 - val_loss: 0.2410 - val_accuracy: 0.9507 - lr: 2.6214e-07\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9609\n",
      "Epoch 114: val_loss did not improve from 0.18875\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.1189 - accuracy: 0.9609 - val_loss: 0.1941 - val_accuracy: 0.9342 - lr: 2.6214e-07\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9691\n",
      "Epoch 115: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.1034 - accuracy: 0.9691 - val_loss: 0.2582 - val_accuracy: 0.9452 - lr: 1.0486e-07\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9725\n",
      "Epoch 116: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.1052 - accuracy: 0.9725 - val_loss: 0.2462 - val_accuracy: 0.9397 - lr: 1.0486e-07\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9670\n",
      "Epoch 117: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1094 - accuracy: 0.9670 - val_loss: 0.2349 - val_accuracy: 0.9233 - lr: 1.0486e-07\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9588\n",
      "Epoch 118: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1192 - accuracy: 0.9588 - val_loss: 0.1962 - val_accuracy: 0.9397 - lr: 1.0486e-07\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9677\n",
      "Epoch 119: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1091 - accuracy: 0.9677 - val_loss: 0.2376 - val_accuracy: 0.9507 - lr: 1.0486e-07\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9670\n",
      "Epoch 120: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1027 - accuracy: 0.9670 - val_loss: 0.2967 - val_accuracy: 0.9288 - lr: 1.0486e-07\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9602\n",
      "Epoch 121: val_loss did not improve from 0.18875\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1278 - accuracy: 0.9602 - val_loss: 0.3135 - val_accuracy: 0.9342 - lr: 1.0486e-07\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9663\n",
      "Epoch 122: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1114 - accuracy: 0.9663 - val_loss: 0.2867 - val_accuracy: 0.9479 - lr: 1.0000e-07\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9622\n",
      "Epoch 123: val_loss did not improve from 0.18875\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.1122 - accuracy: 0.9622 - val_loss: 0.2762 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9684\n",
      "Epoch 124: val_loss improved from 0.18875 to 0.18294, saving model to .\\ResNet50_KFold_ver1_fold1.hdf5\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 0.0993 - accuracy: 0.9684 - val_loss: 0.1829 - val_accuracy: 0.9507 - lr: 1.0000e-07\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9609\n",
      "Epoch 125: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1246 - accuracy: 0.9609 - val_loss: 0.2274 - val_accuracy: 0.9562 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9663\n",
      "Epoch 126: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.2211 - val_accuracy: 0.9425 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9684\n",
      "Epoch 127: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 44s 962ms/step - loss: 0.1020 - accuracy: 0.9684 - val_loss: 0.2624 - val_accuracy: 0.9397 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9698\n",
      "Epoch 128: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 39s 840ms/step - loss: 0.1002 - accuracy: 0.9698 - val_loss: 0.2864 - val_accuracy: 0.9315 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9677\n",
      "Epoch 129: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 0.2030 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9622\n",
      "Epoch 130: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.2684 - val_accuracy: 0.9370 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9615\n",
      "Epoch 131: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.1078 - accuracy: 0.9615 - val_loss: 0.2436 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9636\n",
      "Epoch 132: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1041 - accuracy: 0.9636 - val_loss: 0.2210 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9609\n",
      "Epoch 133: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 703ms/step - loss: 0.1173 - accuracy: 0.9609 - val_loss: 0.2195 - val_accuracy: 0.9370 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9684\n",
      "Epoch 134: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1025 - accuracy: 0.9684 - val_loss: 0.2848 - val_accuracy: 0.9342 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9629\n",
      "Epoch 135: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.1135 - accuracy: 0.9629 - val_loss: 0.2341 - val_accuracy: 0.9370 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9684\n",
      "Epoch 136: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1038 - accuracy: 0.9684 - val_loss: 0.2480 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9588\n",
      "Epoch 137: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1179 - accuracy: 0.9588 - val_loss: 0.2582 - val_accuracy: 0.9425 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9691\n",
      "Epoch 138: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 703ms/step - loss: 0.1122 - accuracy: 0.9691 - val_loss: 0.2344 - val_accuracy: 0.9425 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9663\n",
      "Epoch 139: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1144 - accuracy: 0.9663 - val_loss: 0.1886 - val_accuracy: 0.9452 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9622\n",
      "Epoch 140: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1099 - accuracy: 0.9622 - val_loss: 0.1874 - val_accuracy: 0.9562 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9657\n",
      "Epoch 141: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.1134 - accuracy: 0.9657 - val_loss: 0.2206 - val_accuracy: 0.9288 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9574\n",
      "Epoch 142: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1176 - accuracy: 0.9574 - val_loss: 0.2013 - val_accuracy: 0.9534 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9657\n",
      "Epoch 143: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1094 - accuracy: 0.9657 - val_loss: 0.1972 - val_accuracy: 0.9562 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9691\n",
      "Epoch 144: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1062 - accuracy: 0.9691 - val_loss: 0.1963 - val_accuracy: 0.9397 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9698\n",
      "Epoch 145: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0932 - accuracy: 0.9698 - val_loss: 0.2746 - val_accuracy: 0.9425 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9670\n",
      "Epoch 146: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1031 - accuracy: 0.9670 - val_loss: 0.2744 - val_accuracy: 0.9479 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9602\n",
      "Epoch 147: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1166 - accuracy: 0.9602 - val_loss: 0.2745 - val_accuracy: 0.9397 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9609\n",
      "Epoch 148: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1210 - accuracy: 0.9609 - val_loss: 0.2431 - val_accuracy: 0.9425 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9629\n",
      "Epoch 149: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.1138 - accuracy: 0.9629 - val_loss: 0.1947 - val_accuracy: 0.9507 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9519\n",
      "Epoch 150: val_loss did not improve from 0.18294\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1270 - accuracy: 0.9519 - val_loss: 0.2323 - val_accuracy: 0.9507 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold: 2\n",
      "Found 1457 validated image filenames.\n",
      "Found 364 validated image filenames.\n",
      "Found 1821 validated image filenames.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          262272      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4)            260         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,858,500\n",
      "Trainable params: 23,805,380\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.9572 - accuracy: 0.6438\n",
      "Epoch 1: val_loss improved from inf to 1698.13904, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 39s 772ms/step - loss: 0.9572 - accuracy: 0.6438 - val_loss: 1698.1390 - val_accuracy: 0.3736 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.8030\n",
      "Epoch 2: val_loss improved from 1698.13904 to 1.28993, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 0.6331 - accuracy: 0.8030 - val_loss: 1.2899 - val_accuracy: 0.3736 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.8408\n",
      "Epoch 3: val_loss did not improve from 1.28993\n",
      "46/46 [==============================] - 34s 735ms/step - loss: 0.5193 - accuracy: 0.8408 - val_loss: 1.3865 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.8456\n",
      "Epoch 4: val_loss did not improve from 1.28993\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.4955 - accuracy: 0.8456 - val_loss: 1.3336 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8717\n",
      "Epoch 5: val_loss improved from 1.28993 to 1.26634, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.4187 - accuracy: 0.8717 - val_loss: 1.2663 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8572\n",
      "Epoch 6: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.4546 - accuracy: 0.8572 - val_loss: 2.3678 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8765\n",
      "Epoch 7: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.4137 - accuracy: 0.8765 - val_loss: 1.5490 - val_accuracy: 0.3736 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8792\n",
      "Epoch 8: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.4009 - accuracy: 0.8792 - val_loss: 1.4196 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8874\n",
      "Epoch 9: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.4197 - accuracy: 0.8874 - val_loss: 1.4947 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.8703\n",
      "Epoch 10: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.4045 - accuracy: 0.8703 - val_loss: 1.6510 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8922\n",
      "Epoch 11: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.3609 - accuracy: 0.8922 - val_loss: 1.3829 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8909\n",
      "Epoch 12: val_loss did not improve from 1.26634\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.3418 - accuracy: 0.8909 - val_loss: 2.1115 - val_accuracy: 0.2582 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9012\n",
      "Epoch 13: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.3011 - accuracy: 0.9012 - val_loss: 1.5131 - val_accuracy: 0.2582 - lr: 4.0000e-04\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.9087\n",
      "Epoch 14: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.2735 - accuracy: 0.9087 - val_loss: 1.4689 - val_accuracy: 0.2582 - lr: 4.0000e-04\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.9032\n",
      "Epoch 15: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 37s 807ms/step - loss: 0.2850 - accuracy: 0.9032 - val_loss: 1.6296 - val_accuracy: 0.2582 - lr: 4.0000e-04\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.9224\n",
      "Epoch 16: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 34s 741ms/step - loss: 0.2647 - accuracy: 0.9224 - val_loss: 1.5278 - val_accuracy: 0.2967 - lr: 4.0000e-04\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9149\n",
      "Epoch 17: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 35s 747ms/step - loss: 0.2703 - accuracy: 0.9149 - val_loss: 1.7327 - val_accuracy: 0.2637 - lr: 4.0000e-04\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9252\n",
      "Epoch 18: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 35s 757ms/step - loss: 0.2367 - accuracy: 0.9252 - val_loss: 1.5951 - val_accuracy: 0.2967 - lr: 4.0000e-04\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9204\n",
      "Epoch 19: val_loss did not improve from 1.26634\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "46/46 [==============================] - 34s 740ms/step - loss: 0.2490 - accuracy: 0.9204 - val_loss: 1.7067 - val_accuracy: 0.3984 - lr: 4.0000e-04\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9293\n",
      "Epoch 20: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 0.2237 - accuracy: 0.9293 - val_loss: 1.6848 - val_accuracy: 0.4863 - lr: 1.6000e-04\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9369\n",
      "Epoch 21: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.1956 - accuracy: 0.9369 - val_loss: 1.7532 - val_accuracy: 0.5330 - lr: 1.6000e-04\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9266\n",
      "Epoch 22: val_loss did not improve from 1.26634\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.2334 - accuracy: 0.9266 - val_loss: 1.4454 - val_accuracy: 0.6071 - lr: 1.6000e-04\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9314\n",
      "Epoch 23: val_loss improved from 1.26634 to 0.68989, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 731ms/step - loss: 0.2019 - accuracy: 0.9314 - val_loss: 0.6899 - val_accuracy: 0.7720 - lr: 1.6000e-04\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9341\n",
      "Epoch 24: val_loss improved from 0.68989 to 0.43508, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 35s 749ms/step - loss: 0.2050 - accuracy: 0.9341 - val_loss: 0.4351 - val_accuracy: 0.8516 - lr: 1.6000e-04\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9396\n",
      "Epoch 25: val_loss improved from 0.43508 to 0.31662, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 739ms/step - loss: 0.1877 - accuracy: 0.9396 - val_loss: 0.3166 - val_accuracy: 0.8846 - lr: 1.6000e-04\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.9327\n",
      "Epoch 26: val_loss did not improve from 0.31662\n",
      "46/46 [==============================] - 34s 743ms/step - loss: 0.2117 - accuracy: 0.9327 - val_loss: 0.3599 - val_accuracy: 0.8819 - lr: 1.6000e-04\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9375\n",
      "Epoch 27: val_loss did not improve from 0.31662\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1867 - accuracy: 0.9375 - val_loss: 0.3469 - val_accuracy: 0.8791 - lr: 1.6000e-04\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9410\n",
      "Epoch 28: val_loss improved from 0.31662 to 0.23718, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 725ms/step - loss: 0.1790 - accuracy: 0.9410 - val_loss: 0.2372 - val_accuracy: 0.9286 - lr: 1.6000e-04\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9437\n",
      "Epoch 29: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.1643 - accuracy: 0.9437 - val_loss: 0.3186 - val_accuracy: 0.8846 - lr: 1.6000e-04\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9410\n",
      "Epoch 30: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 32s 703ms/step - loss: 0.1769 - accuracy: 0.9410 - val_loss: 0.2692 - val_accuracy: 0.9066 - lr: 1.6000e-04\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9369\n",
      "Epoch 31: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 33s 724ms/step - loss: 0.1868 - accuracy: 0.9369 - val_loss: 0.2462 - val_accuracy: 0.9176 - lr: 1.6000e-04\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9321\n",
      "Epoch 32: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1842 - accuracy: 0.9321 - val_loss: 0.2871 - val_accuracy: 0.9066 - lr: 1.6000e-04\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9403\n",
      "Epoch 33: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 0.1813 - accuracy: 0.9403 - val_loss: 0.2615 - val_accuracy: 0.9148 - lr: 1.6000e-04\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9458\n",
      "Epoch 34: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1749 - accuracy: 0.9458 - val_loss: 0.2524 - val_accuracy: 0.9066 - lr: 1.6000e-04\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9526\n",
      "Epoch 35: val_loss did not improve from 0.23718\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1413 - accuracy: 0.9526 - val_loss: 0.4745 - val_accuracy: 0.8791 - lr: 1.6000e-04\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9465\n",
      "Epoch 36: val_loss did not improve from 0.23718\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.1645 - accuracy: 0.9465 - val_loss: 0.2695 - val_accuracy: 0.9203 - lr: 6.4000e-05\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.9382\n",
      "Epoch 37: val_loss improved from 0.23718 to 0.23142, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 719ms/step - loss: 0.1921 - accuracy: 0.9382 - val_loss: 0.2314 - val_accuracy: 0.9258 - lr: 6.4000e-05\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9499\n",
      "Epoch 38: val_loss did not improve from 0.23142\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.1574 - accuracy: 0.9499 - val_loss: 0.2359 - val_accuracy: 0.9121 - lr: 6.4000e-05\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9506\n",
      "Epoch 39: val_loss improved from 0.23142 to 0.22686, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 0.1679 - accuracy: 0.9506 - val_loss: 0.2269 - val_accuracy: 0.9203 - lr: 6.4000e-05\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9506\n",
      "Epoch 40: val_loss improved from 0.22686 to 0.22041, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 730ms/step - loss: 0.1484 - accuracy: 0.9506 - val_loss: 0.2204 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9465\n",
      "Epoch 41: val_loss improved from 0.22041 to 0.21575, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 730ms/step - loss: 0.1487 - accuracy: 0.9465 - val_loss: 0.2157 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9396\n",
      "Epoch 42: val_loss did not improve from 0.21575\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.1739 - accuracy: 0.9396 - val_loss: 0.3899 - val_accuracy: 0.8654 - lr: 6.4000e-05\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9444\n",
      "Epoch 43: val_loss did not improve from 0.21575\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.1559 - accuracy: 0.9444 - val_loss: 0.3125 - val_accuracy: 0.8984 - lr: 6.4000e-05\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9506\n",
      "Epoch 44: val_loss did not improve from 0.21575\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1482 - accuracy: 0.9506 - val_loss: 0.2303 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9465\n",
      "Epoch 45: val_loss did not improve from 0.21575\n",
      "46/46 [==============================] - 33s 711ms/step - loss: 0.1540 - accuracy: 0.9465 - val_loss: 0.2905 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9417\n",
      "Epoch 46: val_loss did not improve from 0.21575\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.1653 - accuracy: 0.9417 - val_loss: 0.2842 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9506\n",
      "Epoch 47: val_loss improved from 0.21575 to 0.21376, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 726ms/step - loss: 0.1497 - accuracy: 0.9506 - val_loss: 0.2138 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9574\n",
      "Epoch 48: val_loss did not improve from 0.21376\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 0.1275 - accuracy: 0.9574 - val_loss: 0.2317 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9472\n",
      "Epoch 49: val_loss did not improve from 0.21376\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 0.1488 - accuracy: 0.9472 - val_loss: 0.2402 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9568\n",
      "Epoch 50: val_loss improved from 0.21376 to 0.20678, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 719ms/step - loss: 0.1471 - accuracy: 0.9568 - val_loss: 0.2068 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9574\n",
      "Epoch 51: val_loss did not improve from 0.20678\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 0.1402 - accuracy: 0.9574 - val_loss: 0.2092 - val_accuracy: 0.9203 - lr: 6.4000e-05\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9636\n",
      "Epoch 52: val_loss did not improve from 0.20678\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1200 - accuracy: 0.9636 - val_loss: 0.2405 - val_accuracy: 0.9203 - lr: 6.4000e-05\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9602\n",
      "Epoch 53: val_loss did not improve from 0.20678\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.1290 - accuracy: 0.9602 - val_loss: 0.2962 - val_accuracy: 0.9258 - lr: 6.4000e-05\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9588\n",
      "Epoch 54: val_loss improved from 0.20678 to 0.20417, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 735ms/step - loss: 0.1132 - accuracy: 0.9588 - val_loss: 0.2042 - val_accuracy: 0.9368 - lr: 6.4000e-05\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9581\n",
      "Epoch 55: val_loss improved from 0.20417 to 0.18052, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 34s 738ms/step - loss: 0.1248 - accuracy: 0.9581 - val_loss: 0.1805 - val_accuracy: 0.9368 - lr: 6.4000e-05\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9526\n",
      "Epoch 56: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.1221 - accuracy: 0.9526 - val_loss: 0.3084 - val_accuracy: 0.9038 - lr: 6.4000e-05\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9581\n",
      "Epoch 57: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1404 - accuracy: 0.9581 - val_loss: 0.3167 - val_accuracy: 0.9093 - lr: 6.4000e-05\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9561\n",
      "Epoch 58: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1280 - accuracy: 0.9561 - val_loss: 0.2429 - val_accuracy: 0.9258 - lr: 6.4000e-05\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9657\n",
      "Epoch 59: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 0.1168 - accuracy: 0.9657 - val_loss: 0.2363 - val_accuracy: 0.9148 - lr: 6.4000e-05\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9547\n",
      "Epoch 60: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 716ms/step - loss: 0.1356 - accuracy: 0.9547 - val_loss: 0.2650 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9513\n",
      "Epoch 61: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1355 - accuracy: 0.9513 - val_loss: 0.2467 - val_accuracy: 0.9093 - lr: 6.4000e-05\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9636\n",
      "Epoch 62: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.2096 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9636\n",
      "Epoch 63: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1092 - accuracy: 0.9636 - val_loss: 0.2262 - val_accuracy: 0.9148 - lr: 2.5600e-05\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9581\n",
      "Epoch 64: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 36s 790ms/step - loss: 0.1123 - accuracy: 0.9581 - val_loss: 0.2076 - val_accuracy: 0.9313 - lr: 2.5600e-05\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9719\n",
      "Epoch 65: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 36s 788ms/step - loss: 0.0958 - accuracy: 0.9719 - val_loss: 0.2170 - val_accuracy: 0.9286 - lr: 2.5600e-05\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9602\n",
      "Epoch 66: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 734ms/step - loss: 0.1147 - accuracy: 0.9602 - val_loss: 0.2246 - val_accuracy: 0.9203 - lr: 2.5600e-05\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9698\n",
      "Epoch 67: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 741ms/step - loss: 0.0984 - accuracy: 0.9698 - val_loss: 0.2055 - val_accuracy: 0.9423 - lr: 2.5600e-05\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9595\n",
      "Epoch 68: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 739ms/step - loss: 0.1146 - accuracy: 0.9595 - val_loss: 0.2809 - val_accuracy: 0.9176 - lr: 2.5600e-05\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9712\n",
      "Epoch 69: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "46/46 [==============================] - 34s 728ms/step - loss: 0.0946 - accuracy: 0.9712 - val_loss: 0.2827 - val_accuracy: 0.9038 - lr: 2.5600e-05\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9623\n",
      "Epoch 70: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 0.1157 - accuracy: 0.9623 - val_loss: 0.1924 - val_accuracy: 0.9286 - lr: 1.0240e-05\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9725\n",
      "Epoch 71: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.0891 - accuracy: 0.9725 - val_loss: 0.2205 - val_accuracy: 0.9286 - lr: 1.0240e-05\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9705\n",
      "Epoch 72: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 0.0919 - accuracy: 0.9705 - val_loss: 0.2552 - val_accuracy: 0.9203 - lr: 1.0240e-05\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9712\n",
      "Epoch 73: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 0.1019 - accuracy: 0.9712 - val_loss: 0.2019 - val_accuracy: 0.9396 - lr: 1.0240e-05\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9636\n",
      "Epoch 74: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.1107 - accuracy: 0.9636 - val_loss: 0.2683 - val_accuracy: 0.9176 - lr: 1.0240e-05\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9629\n",
      "Epoch 75: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 698ms/step - loss: 0.1009 - accuracy: 0.9629 - val_loss: 0.2065 - val_accuracy: 0.9121 - lr: 1.0240e-05\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9636\n",
      "Epoch 76: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.0950 - accuracy: 0.9636 - val_loss: 0.2416 - val_accuracy: 0.9313 - lr: 1.0240e-05\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9698\n",
      "Epoch 77: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 0.0947 - accuracy: 0.9698 - val_loss: 0.2357 - val_accuracy: 0.9286 - lr: 4.0960e-06\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9664\n",
      "Epoch 78: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.0908 - accuracy: 0.9664 - val_loss: 0.2021 - val_accuracy: 0.9231 - lr: 4.0960e-06\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9671\n",
      "Epoch 79: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.0943 - accuracy: 0.9671 - val_loss: 0.2111 - val_accuracy: 0.9286 - lr: 4.0960e-06\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9643\n",
      "Epoch 80: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.1133 - accuracy: 0.9643 - val_loss: 0.2486 - val_accuracy: 0.9286 - lr: 4.0960e-06\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9664\n",
      "Epoch 81: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.0846 - accuracy: 0.9664 - val_loss: 0.2170 - val_accuracy: 0.9286 - lr: 4.0960e-06\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9725\n",
      "Epoch 82: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.0902 - accuracy: 0.9725 - val_loss: 0.2575 - val_accuracy: 0.9286 - lr: 4.0960e-06\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9698\n",
      "Epoch 83: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.1001 - accuracy: 0.9698 - val_loss: 0.3056 - val_accuracy: 0.9011 - lr: 4.0960e-06\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9705\n",
      "Epoch 84: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 724ms/step - loss: 0.0939 - accuracy: 0.9705 - val_loss: 0.2755 - val_accuracy: 0.9066 - lr: 1.6384e-06\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9609\n",
      "Epoch 85: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 731ms/step - loss: 0.1140 - accuracy: 0.9609 - val_loss: 0.2306 - val_accuracy: 0.9258 - lr: 1.6384e-06\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9725\n",
      "Epoch 86: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.0891 - accuracy: 0.9725 - val_loss: 0.2073 - val_accuracy: 0.9286 - lr: 1.6384e-06\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9677\n",
      "Epoch 87: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.1027 - accuracy: 0.9677 - val_loss: 0.1941 - val_accuracy: 0.9368 - lr: 1.6384e-06\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9677\n",
      "Epoch 88: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.1037 - accuracy: 0.9677 - val_loss: 0.2586 - val_accuracy: 0.9148 - lr: 1.6384e-06\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9705\n",
      "Epoch 89: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.0865 - accuracy: 0.9705 - val_loss: 0.2295 - val_accuracy: 0.9231 - lr: 1.6384e-06\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9609\n",
      "Epoch 90: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "46/46 [==============================] - 34s 734ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 0.2085 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9650\n",
      "Epoch 91: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 727ms/step - loss: 0.0985 - accuracy: 0.9650 - val_loss: 0.2174 - val_accuracy: 0.9286 - lr: 6.5536e-07\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9650\n",
      "Epoch 92: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 721ms/step - loss: 0.1053 - accuracy: 0.9650 - val_loss: 0.2820 - val_accuracy: 0.9286 - lr: 6.5536e-07\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9671\n",
      "Epoch 93: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.0909 - accuracy: 0.9671 - val_loss: 0.2540 - val_accuracy: 0.9176 - lr: 6.5536e-07\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9753\n",
      "Epoch 94: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 710ms/step - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.2535 - val_accuracy: 0.9148 - lr: 6.5536e-07\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9719\n",
      "Epoch 95: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.0987 - accuracy: 0.9719 - val_loss: 0.2572 - val_accuracy: 0.9258 - lr: 6.5536e-07\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9629\n",
      "Epoch 96: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 722ms/step - loss: 0.1060 - accuracy: 0.9629 - val_loss: 0.2595 - val_accuracy: 0.9231 - lr: 6.5536e-07\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9636\n",
      "Epoch 97: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1141 - accuracy: 0.9636 - val_loss: 0.2185 - val_accuracy: 0.9286 - lr: 6.5536e-07\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9616\n",
      "Epoch 98: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 738ms/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.2305 - val_accuracy: 0.9231 - lr: 2.6214e-07\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9691\n",
      "Epoch 99: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 36s 771ms/step - loss: 0.0940 - accuracy: 0.9691 - val_loss: 0.1971 - val_accuracy: 0.9313 - lr: 2.6214e-07\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9684\n",
      "Epoch 100: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 734ms/step - loss: 0.0909 - accuracy: 0.9684 - val_loss: 0.2434 - val_accuracy: 0.9121 - lr: 2.6214e-07\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9698\n",
      "Epoch 101: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 34s 740ms/step - loss: 0.0900 - accuracy: 0.9698 - val_loss: 0.2685 - val_accuracy: 0.9176 - lr: 2.6214e-07\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9719\n",
      "Epoch 102: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 35s 748ms/step - loss: 0.0821 - accuracy: 0.9719 - val_loss: 0.2502 - val_accuracy: 0.9286 - lr: 2.6214e-07\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9705\n",
      "Epoch 103: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 35s 763ms/step - loss: 0.0881 - accuracy: 0.9705 - val_loss: 0.2376 - val_accuracy: 0.9203 - lr: 2.6214e-07\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9712\n",
      "Epoch 104: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "46/46 [==============================] - 34s 735ms/step - loss: 0.0972 - accuracy: 0.9712 - val_loss: 0.2540 - val_accuracy: 0.9176 - lr: 2.6214e-07\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9643\n",
      "Epoch 105: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 36s 775ms/step - loss: 0.1011 - accuracy: 0.9643 - val_loss: 0.2565 - val_accuracy: 0.9121 - lr: 1.0486e-07\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9657\n",
      "Epoch 106: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 35s 764ms/step - loss: 0.0970 - accuracy: 0.9657 - val_loss: 0.2396 - val_accuracy: 0.9066 - lr: 1.0486e-07\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9664\n",
      "Epoch 107: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 0.0954 - accuracy: 0.9664 - val_loss: 0.2933 - val_accuracy: 0.9066 - lr: 1.0486e-07\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9657\n",
      "Epoch 108: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 0.1000 - accuracy: 0.9657 - val_loss: 0.2213 - val_accuracy: 0.9313 - lr: 1.0486e-07\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9671\n",
      "Epoch 109: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 661ms/step - loss: 0.1029 - accuracy: 0.9671 - val_loss: 0.2413 - val_accuracy: 0.9231 - lr: 1.0486e-07\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9760\n",
      "Epoch 110: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 30s 651ms/step - loss: 0.0776 - accuracy: 0.9760 - val_loss: 0.2198 - val_accuracy: 0.9286 - lr: 1.0486e-07\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9746\n",
      "Epoch 111: val_loss did not improve from 0.18052\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.0921 - accuracy: 0.9746 - val_loss: 0.2500 - val_accuracy: 0.9258 - lr: 1.0486e-07\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9684\n",
      "Epoch 112: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0910 - accuracy: 0.9684 - val_loss: 0.2325 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9684\n",
      "Epoch 113: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0936 - accuracy: 0.9684 - val_loss: 0.3000 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9719\n",
      "Epoch 114: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0869 - accuracy: 0.9719 - val_loss: 0.2663 - val_accuracy: 0.9148 - lr: 1.0000e-07\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9677\n",
      "Epoch 115: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.0945 - accuracy: 0.9677 - val_loss: 0.2048 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9698\n",
      "Epoch 116: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.0869 - accuracy: 0.9698 - val_loss: 0.2694 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9739\n",
      "Epoch 117: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.0802 - accuracy: 0.9739 - val_loss: 0.2065 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9602\n",
      "Epoch 118: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.1157 - accuracy: 0.9602 - val_loss: 0.2012 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9705\n",
      "Epoch 119: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 713ms/step - loss: 0.0927 - accuracy: 0.9705 - val_loss: 0.2458 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9691\n",
      "Epoch 120: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.0904 - accuracy: 0.9691 - val_loss: 0.1995 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9671\n",
      "Epoch 121: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1036 - accuracy: 0.9671 - val_loss: 0.2391 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9636\n",
      "Epoch 122: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.0954 - accuracy: 0.9636 - val_loss: 0.2094 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9698\n",
      "Epoch 123: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.0973 - accuracy: 0.9698 - val_loss: 0.2376 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9684\n",
      "Epoch 124: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.2471 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9684\n",
      "Epoch 125: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.0996 - accuracy: 0.9684 - val_loss: 0.2754 - val_accuracy: 0.9066 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9677\n",
      "Epoch 126: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.0986 - accuracy: 0.9677 - val_loss: 0.2771 - val_accuracy: 0.9148 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9677\n",
      "Epoch 127: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0919 - accuracy: 0.9677 - val_loss: 0.1912 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9684\n",
      "Epoch 128: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0938 - accuracy: 0.9684 - val_loss: 0.2112 - val_accuracy: 0.9176 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9588\n",
      "Epoch 129: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1057 - accuracy: 0.9588 - val_loss: 0.1990 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9671\n",
      "Epoch 130: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.1079 - accuracy: 0.9671 - val_loss: 0.2487 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9636\n",
      "Epoch 131: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.1005 - accuracy: 0.9636 - val_loss: 0.2772 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9643\n",
      "Epoch 132: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 0.1115 - accuracy: 0.9643 - val_loss: 0.2680 - val_accuracy: 0.9066 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9725\n",
      "Epoch 133: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 35s 752ms/step - loss: 0.0761 - accuracy: 0.9725 - val_loss: 0.2343 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9643\n",
      "Epoch 134: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 696ms/step - loss: 0.1073 - accuracy: 0.9643 - val_loss: 0.2627 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9643\n",
      "Epoch 135: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 703ms/step - loss: 0.1072 - accuracy: 0.9643 - val_loss: 0.2148 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9609\n",
      "Epoch 136: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1145 - accuracy: 0.9609 - val_loss: 0.2149 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9767\n",
      "Epoch 137: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 0.2352 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9643\n",
      "Epoch 138: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.1077 - accuracy: 0.9643 - val_loss: 0.2047 - val_accuracy: 0.9423 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9753\n",
      "Epoch 139: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.0865 - accuracy: 0.9753 - val_loss: 0.3097 - val_accuracy: 0.9066 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9684\n",
      "Epoch 140: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1092 - accuracy: 0.9684 - val_loss: 0.2376 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9691\n",
      "Epoch 141: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 718ms/step - loss: 0.0922 - accuracy: 0.9691 - val_loss: 0.1942 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9712\n",
      "Epoch 142: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 35s 760ms/step - loss: 0.0858 - accuracy: 0.9712 - val_loss: 0.2286 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9684\n",
      "Epoch 143: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.0943 - accuracy: 0.9684 - val_loss: 0.2376 - val_accuracy: 0.9121 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9629\n",
      "Epoch 144: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1092 - accuracy: 0.9629 - val_loss: 0.2145 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9698\n",
      "Epoch 145: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1024 - accuracy: 0.9698 - val_loss: 0.2275 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9760\n",
      "Epoch 146: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.0786 - accuracy: 0.9760 - val_loss: 0.2277 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9657\n",
      "Epoch 147: val_loss did not improve from 0.18052\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1062 - accuracy: 0.9657 - val_loss: 0.2518 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9671\n",
      "Epoch 148: val_loss improved from 0.18052 to 0.17261, saving model to .\\ResNet50_KFold_ver1_fold2.hdf5\n",
      "46/46 [==============================] - 33s 720ms/step - loss: 0.1005 - accuracy: 0.9671 - val_loss: 0.1726 - val_accuracy: 0.9505 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9636\n",
      "Epoch 149: val_loss did not improve from 0.17261\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.1074 - accuracy: 0.9636 - val_loss: 0.2085 - val_accuracy: 0.9176 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9664\n",
      "Epoch 150: val_loss did not improve from 0.17261\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0978 - accuracy: 0.9664 - val_loss: 0.2560 - val_accuracy: 0.9203 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold: 3\n",
      "Found 1457 validated image filenames.\n",
      "Found 364 validated image filenames.\n",
      "Found 1821 validated image filenames.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          262272      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           8256        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 4)            260         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,858,500\n",
      "Trainable params: 23,805,380\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.9697 - accuracy: 0.6699\n",
      "Epoch 1: val_loss improved from inf to 18.20617, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 37s 734ms/step - loss: 0.9697 - accuracy: 0.6699 - val_loss: 18.2062 - val_accuracy: 0.3462 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7879\n",
      "Epoch 2: val_loss improved from 18.20617 to 1.92527, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.6452 - accuracy: 0.7879 - val_loss: 1.9253 - val_accuracy: 0.3407 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8325\n",
      "Epoch 3: val_loss did not improve from 1.92527\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 0.5422 - accuracy: 0.8325 - val_loss: 2.2112 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8710\n",
      "Epoch 4: val_loss improved from 1.92527 to 1.67920, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 35s 753ms/step - loss: 0.4424 - accuracy: 0.8710 - val_loss: 1.6792 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8552\n",
      "Epoch 5: val_loss did not improve from 1.67920\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.4737 - accuracy: 0.8552 - val_loss: 6.9704 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8634\n",
      "Epoch 6: val_loss improved from 1.67920 to 1.35471, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 32s 701ms/step - loss: 0.4456 - accuracy: 0.8634 - val_loss: 1.3547 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8751\n",
      "Epoch 7: val_loss did not improve from 1.35471\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.4146 - accuracy: 0.8751 - val_loss: 1.3721 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8730\n",
      "Epoch 8: val_loss improved from 1.35471 to 1.27695, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.3871 - accuracy: 0.8730 - val_loss: 1.2769 - val_accuracy: 0.3407 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8717\n",
      "Epoch 9: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.4297 - accuracy: 0.8717 - val_loss: 1.4911 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8737\n",
      "Epoch 10: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.4024 - accuracy: 0.8737 - val_loss: 1.3681 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8922\n",
      "Epoch 11: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 0.3482 - accuracy: 0.8922 - val_loss: 2.0689 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8936\n",
      "Epoch 12: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.3679 - accuracy: 0.8936 - val_loss: 1.5965 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8874\n",
      "Epoch 13: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.3496 - accuracy: 0.8874 - val_loss: 1.5512 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.8895\n",
      "Epoch 14: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 708ms/step - loss: 0.3613 - accuracy: 0.8895 - val_loss: 1.5609 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8895\n",
      "Epoch 15: val_loss did not improve from 1.27695\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "46/46 [==============================] - 34s 732ms/step - loss: 0.3504 - accuracy: 0.8895 - val_loss: 1.5087 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.9060\n",
      "Epoch 16: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.2938 - accuracy: 0.9060 - val_loss: 1.5961 - val_accuracy: 0.2720 - lr: 4.0000e-04\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9128\n",
      "Epoch 17: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 0.2842 - accuracy: 0.9128 - val_loss: 1.5786 - val_accuracy: 0.3214 - lr: 4.0000e-04\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9108\n",
      "Epoch 18: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 34s 729ms/step - loss: 0.2566 - accuracy: 0.9108 - val_loss: 1.6565 - val_accuracy: 0.3104 - lr: 4.0000e-04\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9128\n",
      "Epoch 19: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 734ms/step - loss: 0.2568 - accuracy: 0.9128 - val_loss: 1.4861 - val_accuracy: 0.4038 - lr: 4.0000e-04\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9142\n",
      "Epoch 20: val_loss did not improve from 1.27695\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.2571 - accuracy: 0.9142 - val_loss: 1.6810 - val_accuracy: 0.5165 - lr: 4.0000e-04\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.9224\n",
      "Epoch 21: val_loss improved from 1.27695 to 1.18417, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 34s 738ms/step - loss: 0.2505 - accuracy: 0.9224 - val_loss: 1.1842 - val_accuracy: 0.6291 - lr: 4.0000e-04\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9348\n",
      "Epoch 22: val_loss improved from 1.18417 to 0.84123, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 34s 737ms/step - loss: 0.2261 - accuracy: 0.9348 - val_loss: 0.8412 - val_accuracy: 0.7418 - lr: 4.0000e-04\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9245\n",
      "Epoch 23: val_loss improved from 0.84123 to 0.82221, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 725ms/step - loss: 0.2399 - accuracy: 0.9245 - val_loss: 0.8222 - val_accuracy: 0.7033 - lr: 4.0000e-04\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9211\n",
      "Epoch 24: val_loss improved from 0.82221 to 0.51505, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 34s 730ms/step - loss: 0.2434 - accuracy: 0.9211 - val_loss: 0.5150 - val_accuracy: 0.8434 - lr: 4.0000e-04\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9272\n",
      "Epoch 25: val_loss improved from 0.51505 to 0.29917, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 705ms/step - loss: 0.2364 - accuracy: 0.9272 - val_loss: 0.2992 - val_accuracy: 0.8956 - lr: 4.0000e-04\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.9197\n",
      "Epoch 26: val_loss did not improve from 0.29917\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.2523 - accuracy: 0.9197 - val_loss: 0.6521 - val_accuracy: 0.8242 - lr: 4.0000e-04\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9279\n",
      "Epoch 27: val_loss did not improve from 0.29917\n",
      "46/46 [==============================] - 33s 707ms/step - loss: 0.2335 - accuracy: 0.9279 - val_loss: 0.3892 - val_accuracy: 0.8929 - lr: 4.0000e-04\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9252\n",
      "Epoch 28: val_loss did not improve from 0.29917\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.2104 - accuracy: 0.9252 - val_loss: 0.3156 - val_accuracy: 0.8984 - lr: 4.0000e-04\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9231\n",
      "Epoch 29: val_loss did not improve from 0.29917\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.2330 - accuracy: 0.9231 - val_loss: 0.3319 - val_accuracy: 0.8956 - lr: 4.0000e-04\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9279\n",
      "Epoch 30: val_loss did not improve from 0.29917\n",
      "46/46 [==============================] - 41s 885ms/step - loss: 0.2214 - accuracy: 0.9279 - val_loss: 0.4100 - val_accuracy: 0.8709 - lr: 4.0000e-04\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9300\n",
      "Epoch 31: val_loss improved from 0.29917 to 0.25659, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 35s 761ms/step - loss: 0.2257 - accuracy: 0.9300 - val_loss: 0.2566 - val_accuracy: 0.9121 - lr: 4.0000e-04\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.9327\n",
      "Epoch 32: val_loss improved from 0.25659 to 0.25650, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 703ms/step - loss: 0.2081 - accuracy: 0.9327 - val_loss: 0.2565 - val_accuracy: 0.9176 - lr: 4.0000e-04\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9286\n",
      "Epoch 33: val_loss improved from 0.25650 to 0.24911, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 703ms/step - loss: 0.2025 - accuracy: 0.9286 - val_loss: 0.2491 - val_accuracy: 0.9148 - lr: 4.0000e-04\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9321\n",
      "Epoch 34: val_loss improved from 0.24911 to 0.23274, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.2084 - accuracy: 0.9321 - val_loss: 0.2327 - val_accuracy: 0.9341 - lr: 4.0000e-04\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9403\n",
      "Epoch 35: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1652 - accuracy: 0.9403 - val_loss: 0.5131 - val_accuracy: 0.8269 - lr: 4.0000e-04\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9286\n",
      "Epoch 36: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 33s 719ms/step - loss: 0.2248 - accuracy: 0.9286 - val_loss: 0.3789 - val_accuracy: 0.8571 - lr: 4.0000e-04\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9272\n",
      "Epoch 37: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.2193 - accuracy: 0.9272 - val_loss: 0.2342 - val_accuracy: 0.9341 - lr: 4.0000e-04\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9423\n",
      "Epoch 38: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 35s 765ms/step - loss: 0.1910 - accuracy: 0.9423 - val_loss: 0.2703 - val_accuracy: 0.9231 - lr: 4.0000e-04\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9417\n",
      "Epoch 39: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1873 - accuracy: 0.9417 - val_loss: 0.4662 - val_accuracy: 0.8379 - lr: 4.0000e-04\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9279\n",
      "Epoch 40: val_loss did not improve from 0.23274\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.2136 - accuracy: 0.9279 - val_loss: 0.5802 - val_accuracy: 0.7857 - lr: 4.0000e-04\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9334\n",
      "Epoch 41: val_loss did not improve from 0.23274\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.2032 - accuracy: 0.9334 - val_loss: 0.3719 - val_accuracy: 0.8874 - lr: 4.0000e-04\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9369\n",
      "Epoch 42: val_loss improved from 0.23274 to 0.21316, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.1890 - accuracy: 0.9369 - val_loss: 0.2132 - val_accuracy: 0.9286 - lr: 1.6000e-04\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9465\n",
      "Epoch 43: val_loss did not improve from 0.21316\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1615 - accuracy: 0.9465 - val_loss: 0.2280 - val_accuracy: 0.9231 - lr: 1.6000e-04\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9540\n",
      "Epoch 44: val_loss improved from 0.21316 to 0.15756, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 709ms/step - loss: 0.1531 - accuracy: 0.9540 - val_loss: 0.1576 - val_accuracy: 0.9451 - lr: 1.6000e-04\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9451\n",
      "Epoch 45: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.1723 - accuracy: 0.9451 - val_loss: 0.2035 - val_accuracy: 0.9258 - lr: 1.6000e-04\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9554\n",
      "Epoch 46: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.1539 - accuracy: 0.9554 - val_loss: 0.2430 - val_accuracy: 0.8984 - lr: 1.6000e-04\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9485\n",
      "Epoch 47: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 34s 738ms/step - loss: 0.1495 - accuracy: 0.9485 - val_loss: 0.1628 - val_accuracy: 0.9451 - lr: 1.6000e-04\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9547\n",
      "Epoch 48: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 36s 776ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.2363 - val_accuracy: 0.9313 - lr: 1.6000e-04\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9506\n",
      "Epoch 49: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 33s 717ms/step - loss: 0.1561 - accuracy: 0.9506 - val_loss: 0.2628 - val_accuracy: 0.9121 - lr: 1.6000e-04\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9526\n",
      "Epoch 50: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.1423 - accuracy: 0.9526 - val_loss: 0.2132 - val_accuracy: 0.9258 - lr: 1.6000e-04\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9472\n",
      "Epoch 51: val_loss did not improve from 0.15756\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1524 - accuracy: 0.9472 - val_loss: 0.2533 - val_accuracy: 0.9231 - lr: 1.6000e-04\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9499\n",
      "Epoch 52: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1477 - accuracy: 0.9499 - val_loss: 0.1938 - val_accuracy: 0.9396 - lr: 6.4000e-05\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9588\n",
      "Epoch 53: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1310 - accuracy: 0.9588 - val_loss: 0.1987 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9533\n",
      "Epoch 54: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.1370 - accuracy: 0.9533 - val_loss: 0.1902 - val_accuracy: 0.9368 - lr: 6.4000e-05\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9547\n",
      "Epoch 55: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1294 - accuracy: 0.9547 - val_loss: 0.1937 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9629\n",
      "Epoch 56: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 698ms/step - loss: 0.1180 - accuracy: 0.9629 - val_loss: 0.1638 - val_accuracy: 0.9396 - lr: 6.4000e-05\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9595\n",
      "Epoch 57: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1248 - accuracy: 0.9595 - val_loss: 0.1796 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9520\n",
      "Epoch 58: val_loss did not improve from 0.15756\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1339 - accuracy: 0.9520 - val_loss: 0.2045 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9561\n",
      "Epoch 59: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1311 - accuracy: 0.9561 - val_loss: 0.2281 - val_accuracy: 0.9451 - lr: 2.5600e-05\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9609\n",
      "Epoch 60: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.1264 - accuracy: 0.9609 - val_loss: 0.2376 - val_accuracy: 0.9313 - lr: 2.5600e-05\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9643\n",
      "Epoch 61: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.1175 - accuracy: 0.9643 - val_loss: 0.1887 - val_accuracy: 0.9341 - lr: 2.5600e-05\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9664\n",
      "Epoch 62: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1120 - accuracy: 0.9664 - val_loss: 0.2038 - val_accuracy: 0.9368 - lr: 2.5600e-05\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9629\n",
      "Epoch 63: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1020 - accuracy: 0.9629 - val_loss: 0.2542 - val_accuracy: 0.9121 - lr: 2.5600e-05\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9657\n",
      "Epoch 64: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1086 - accuracy: 0.9657 - val_loss: 0.2324 - val_accuracy: 0.9231 - lr: 2.5600e-05\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9629\n",
      "Epoch 65: val_loss did not improve from 0.15756\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "46/46 [==============================] - 33s 706ms/step - loss: 0.1142 - accuracy: 0.9629 - val_loss: 0.1765 - val_accuracy: 0.9451 - lr: 2.5600e-05\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9705\n",
      "Epoch 66: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 33s 712ms/step - loss: 0.1048 - accuracy: 0.9705 - val_loss: 0.1925 - val_accuracy: 0.9423 - lr: 1.0240e-05\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9547\n",
      "Epoch 67: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 34s 733ms/step - loss: 0.1291 - accuracy: 0.9547 - val_loss: 0.2256 - val_accuracy: 0.9368 - lr: 1.0240e-05\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9664\n",
      "Epoch 68: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 34s 730ms/step - loss: 0.1055 - accuracy: 0.9664 - val_loss: 0.2094 - val_accuracy: 0.9203 - lr: 1.0240e-05\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9671\n",
      "Epoch 69: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.0957 - accuracy: 0.9671 - val_loss: 0.2116 - val_accuracy: 0.9451 - lr: 1.0240e-05\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9609\n",
      "Epoch 70: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.1064 - accuracy: 0.9609 - val_loss: 0.1751 - val_accuracy: 0.9396 - lr: 1.0240e-05\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9712\n",
      "Epoch 71: val_loss did not improve from 0.15756\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.0919 - accuracy: 0.9712 - val_loss: 0.1801 - val_accuracy: 0.9423 - lr: 1.0240e-05\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9636\n",
      "Epoch 72: val_loss improved from 0.15756 to 0.15671, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 34s 735ms/step - loss: 0.1043 - accuracy: 0.9636 - val_loss: 0.1567 - val_accuracy: 0.9478 - lr: 1.0240e-05\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9671\n",
      "Epoch 73: val_loss did not improve from 0.15671\n",
      "46/46 [==============================] - 32s 711ms/step - loss: 0.0954 - accuracy: 0.9671 - val_loss: 0.1681 - val_accuracy: 0.9560 - lr: 1.0240e-05\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9581\n",
      "Epoch 74: val_loss did not improve from 0.15671\n",
      "46/46 [==============================] - 34s 733ms/step - loss: 0.1147 - accuracy: 0.9581 - val_loss: 0.1778 - val_accuracy: 0.9533 - lr: 1.0240e-05\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9719\n",
      "Epoch 75: val_loss did not improve from 0.15671\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.1004 - accuracy: 0.9719 - val_loss: 0.1974 - val_accuracy: 0.9451 - lr: 1.0240e-05\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9609\n",
      "Epoch 76: val_loss did not improve from 0.15671\n",
      "46/46 [==============================] - 33s 715ms/step - loss: 0.1194 - accuracy: 0.9609 - val_loss: 0.2194 - val_accuracy: 0.9341 - lr: 1.0240e-05\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9643\n",
      "Epoch 77: val_loss improved from 0.15671 to 0.14945, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 34s 727ms/step - loss: 0.1082 - accuracy: 0.9643 - val_loss: 0.1494 - val_accuracy: 0.9643 - lr: 1.0240e-05\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9629\n",
      "Epoch 78: val_loss did not improve from 0.14945\n",
      "46/46 [==============================] - 32s 698ms/step - loss: 0.1145 - accuracy: 0.9629 - val_loss: 0.1521 - val_accuracy: 0.9588 - lr: 1.0240e-05\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9677\n",
      "Epoch 79: val_loss did not improve from 0.14945\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.1073 - accuracy: 0.9677 - val_loss: 0.1870 - val_accuracy: 0.9423 - lr: 1.0240e-05\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9636\n",
      "Epoch 80: val_loss improved from 0.14945 to 0.14557, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 725ms/step - loss: 0.1036 - accuracy: 0.9636 - val_loss: 0.1456 - val_accuracy: 0.9560 - lr: 1.0240e-05\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9712\n",
      "Epoch 81: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.0950 - accuracy: 0.9712 - val_loss: 0.2225 - val_accuracy: 0.9423 - lr: 1.0240e-05\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9650\n",
      "Epoch 82: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1062 - accuracy: 0.9650 - val_loss: 0.2625 - val_accuracy: 0.9176 - lr: 1.0240e-05\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9657\n",
      "Epoch 83: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1056 - accuracy: 0.9657 - val_loss: 0.1558 - val_accuracy: 0.9478 - lr: 1.0240e-05\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9588\n",
      "Epoch 84: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1108 - accuracy: 0.9588 - val_loss: 0.2393 - val_accuracy: 0.9505 - lr: 1.0240e-05\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9725\n",
      "Epoch 85: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.0915 - accuracy: 0.9725 - val_loss: 0.2068 - val_accuracy: 0.9368 - lr: 1.0240e-05\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9684\n",
      "Epoch 86: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0958 - accuracy: 0.9684 - val_loss: 0.2067 - val_accuracy: 0.9396 - lr: 1.0240e-05\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9671\n",
      "Epoch 87: val_loss did not improve from 0.14557\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.0977 - accuracy: 0.9671 - val_loss: 0.2172 - val_accuracy: 0.9341 - lr: 1.0240e-05\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9643\n",
      "Epoch 88: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 33s 714ms/step - loss: 0.1039 - accuracy: 0.9643 - val_loss: 0.2148 - val_accuracy: 0.9341 - lr: 4.0960e-06\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9657\n",
      "Epoch 89: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.1140 - accuracy: 0.9657 - val_loss: 0.1546 - val_accuracy: 0.9533 - lr: 4.0960e-06\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9677\n",
      "Epoch 90: val_loss did not improve from 0.14557\n",
      "46/46 [==============================] - 31s 687ms/step - loss: 0.1070 - accuracy: 0.9677 - val_loss: 0.1911 - val_accuracy: 0.9478 - lr: 4.0960e-06\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9609\n",
      "Epoch 91: val_loss improved from 0.14557 to 0.13079, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 32s 700ms/step - loss: 0.1187 - accuracy: 0.9609 - val_loss: 0.1308 - val_accuracy: 0.9615 - lr: 4.0960e-06\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9636\n",
      "Epoch 92: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1014 - accuracy: 0.9636 - val_loss: 0.1689 - val_accuracy: 0.9533 - lr: 4.0960e-06\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9657\n",
      "Epoch 93: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1041 - accuracy: 0.9657 - val_loss: 0.2046 - val_accuracy: 0.9423 - lr: 4.0960e-06\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9712\n",
      "Epoch 94: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1007 - accuracy: 0.9712 - val_loss: 0.1743 - val_accuracy: 0.9368 - lr: 4.0960e-06\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9691\n",
      "Epoch 95: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0949 - accuracy: 0.9691 - val_loss: 0.1917 - val_accuracy: 0.9368 - lr: 4.0960e-06\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9677\n",
      "Epoch 96: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.0947 - accuracy: 0.9677 - val_loss: 0.2029 - val_accuracy: 0.9368 - lr: 4.0960e-06\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9636\n",
      "Epoch 97: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1079 - accuracy: 0.9636 - val_loss: 0.2619 - val_accuracy: 0.9313 - lr: 4.0960e-06\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9698\n",
      "Epoch 98: val_loss did not improve from 0.13079\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.1977 - val_accuracy: 0.9478 - lr: 4.0960e-06\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9677\n",
      "Epoch 99: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 0.1646 - val_accuracy: 0.9588 - lr: 1.6384e-06\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9705\n",
      "Epoch 100: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.2218 - val_accuracy: 0.9451 - lr: 1.6384e-06\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9691\n",
      "Epoch 101: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.0899 - accuracy: 0.9691 - val_loss: 0.1823 - val_accuracy: 0.9451 - lr: 1.6384e-06\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9650\n",
      "Epoch 102: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 687ms/step - loss: 0.1058 - accuracy: 0.9650 - val_loss: 0.2612 - val_accuracy: 0.9313 - lr: 1.6384e-06\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9588\n",
      "Epoch 103: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1014 - accuracy: 0.9588 - val_loss: 0.1859 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9691\n",
      "Epoch 104: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0860 - accuracy: 0.9691 - val_loss: 0.1802 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9636\n",
      "Epoch 105: val_loss did not improve from 0.13079\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1023 - accuracy: 0.9636 - val_loss: 0.1962 - val_accuracy: 0.9451 - lr: 1.6384e-06\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9664\n",
      "Epoch 106: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1075 - accuracy: 0.9664 - val_loss: 0.2228 - val_accuracy: 0.9396 - lr: 6.5536e-07\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9671\n",
      "Epoch 107: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1021 - accuracy: 0.9671 - val_loss: 0.1639 - val_accuracy: 0.9505 - lr: 6.5536e-07\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9684\n",
      "Epoch 108: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.0996 - accuracy: 0.9684 - val_loss: 0.2017 - val_accuracy: 0.9368 - lr: 6.5536e-07\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9725\n",
      "Epoch 109: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0878 - accuracy: 0.9725 - val_loss: 0.1595 - val_accuracy: 0.9533 - lr: 6.5536e-07\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9677\n",
      "Epoch 110: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1001 - accuracy: 0.9677 - val_loss: 0.1915 - val_accuracy: 0.9505 - lr: 6.5536e-07\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9629\n",
      "Epoch 111: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.1082 - accuracy: 0.9629 - val_loss: 0.2232 - val_accuracy: 0.9286 - lr: 6.5536e-07\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9629\n",
      "Epoch 112: val_loss did not improve from 0.13079\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.1079 - accuracy: 0.9629 - val_loss: 0.1791 - val_accuracy: 0.9423 - lr: 6.5536e-07\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9650\n",
      "Epoch 113: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1124 - accuracy: 0.9650 - val_loss: 0.1872 - val_accuracy: 0.9396 - lr: 2.6214e-07\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9602\n",
      "Epoch 114: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1117 - accuracy: 0.9602 - val_loss: 0.2109 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9629\n",
      "Epoch 115: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.1929 - val_accuracy: 0.9505 - lr: 2.6214e-07\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9698\n",
      "Epoch 116: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 0.1918 - val_accuracy: 0.9478 - lr: 2.6214e-07\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9712\n",
      "Epoch 117: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.0949 - accuracy: 0.9712 - val_loss: 0.1853 - val_accuracy: 0.9451 - lr: 2.6214e-07\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9739\n",
      "Epoch 118: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.0819 - accuracy: 0.9739 - val_loss: 0.1874 - val_accuracy: 0.9396 - lr: 2.6214e-07\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9712\n",
      "Epoch 119: val_loss did not improve from 0.13079\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1021 - accuracy: 0.9712 - val_loss: 0.1921 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9650\n",
      "Epoch 120: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.1056 - accuracy: 0.9650 - val_loss: 0.2172 - val_accuracy: 0.9505 - lr: 1.0486e-07\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9657\n",
      "Epoch 121: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.1026 - accuracy: 0.9657 - val_loss: 0.1934 - val_accuracy: 0.9423 - lr: 1.0486e-07\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9650\n",
      "Epoch 122: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 688ms/step - loss: 0.0937 - accuracy: 0.9650 - val_loss: 0.1626 - val_accuracy: 0.9533 - lr: 1.0486e-07\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9712\n",
      "Epoch 123: val_loss did not improve from 0.13079\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.0968 - accuracy: 0.9712 - val_loss: 0.1935 - val_accuracy: 0.9368 - lr: 1.0486e-07\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9643\n",
      "Epoch 124: val_loss improved from 0.13079 to 0.12689, saving model to .\\ResNet50_KFold_ver1_fold3.hdf5\n",
      "46/46 [==============================] - 33s 704ms/step - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.1269 - val_accuracy: 0.9615 - lr: 1.0486e-07\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9725\n",
      "Epoch 125: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0843 - accuracy: 0.9725 - val_loss: 0.2076 - val_accuracy: 0.9451 - lr: 1.0486e-07\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9719\n",
      "Epoch 126: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.0798 - accuracy: 0.9719 - val_loss: 0.1718 - val_accuracy: 0.9451 - lr: 1.0486e-07\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9698\n",
      "Epoch 127: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0953 - accuracy: 0.9698 - val_loss: 0.2007 - val_accuracy: 0.9396 - lr: 1.0486e-07\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9691\n",
      "Epoch 128: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0882 - accuracy: 0.9691 - val_loss: 0.1829 - val_accuracy: 0.9478 - lr: 1.0486e-07\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9664\n",
      "Epoch 129: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0989 - accuracy: 0.9664 - val_loss: 0.2355 - val_accuracy: 0.9368 - lr: 1.0486e-07\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9629\n",
      "Epoch 130: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1122 - accuracy: 0.9629 - val_loss: 0.2316 - val_accuracy: 0.9258 - lr: 1.0486e-07\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9691\n",
      "Epoch 131: val_loss did not improve from 0.12689\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.1051 - accuracy: 0.9691 - val_loss: 0.1819 - val_accuracy: 0.9396 - lr: 1.0486e-07\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9595\n",
      "Epoch 132: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1259 - accuracy: 0.9595 - val_loss: 0.2143 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9719\n",
      "Epoch 133: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.1761 - val_accuracy: 0.9423 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9732\n",
      "Epoch 134: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0882 - accuracy: 0.9732 - val_loss: 0.2000 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9650\n",
      "Epoch 135: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1085 - accuracy: 0.9650 - val_loss: 0.1918 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9691\n",
      "Epoch 136: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.1035 - accuracy: 0.9691 - val_loss: 0.1428 - val_accuracy: 0.9588 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9623\n",
      "Epoch 137: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0992 - accuracy: 0.9623 - val_loss: 0.1887 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9636\n",
      "Epoch 138: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.1060 - accuracy: 0.9636 - val_loss: 0.2100 - val_accuracy: 0.9423 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9712\n",
      "Epoch 139: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0929 - accuracy: 0.9712 - val_loss: 0.1732 - val_accuracy: 0.9451 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9671\n",
      "Epoch 140: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0999 - accuracy: 0.9671 - val_loss: 0.2122 - val_accuracy: 0.9423 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9739\n",
      "Epoch 141: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0893 - accuracy: 0.9739 - val_loss: 0.1914 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9657\n",
      "Epoch 142: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 688ms/step - loss: 0.1078 - accuracy: 0.9657 - val_loss: 0.1912 - val_accuracy: 0.9505 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9691\n",
      "Epoch 143: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0980 - accuracy: 0.9691 - val_loss: 0.1624 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9623\n",
      "Epoch 144: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1099 - accuracy: 0.9623 - val_loss: 0.2015 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9698\n",
      "Epoch 145: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0848 - accuracy: 0.9698 - val_loss: 0.1582 - val_accuracy: 0.9423 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9725\n",
      "Epoch 146: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 0.2135 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9650\n",
      "Epoch 147: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.1356 - val_accuracy: 0.9588 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9650\n",
      "Epoch 148: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1038 - accuracy: 0.9650 - val_loss: 0.1858 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9636\n",
      "Epoch 149: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1009 - accuracy: 0.9636 - val_loss: 0.2153 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9691\n",
      "Epoch 150: val_loss did not improve from 0.12689\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1084 - accuracy: 0.9691 - val_loss: 0.2049 - val_accuracy: 0.9286 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold: 4\n",
      "Found 1457 validated image filenames.\n",
      "Found 364 validated image filenames.\n",
      "Found 1821 validated image filenames.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          262272      ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           8256        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 4)            260         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,858,500\n",
      "Trainable params: 23,805,380\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.6424\n",
      "Epoch 1: val_loss improved from inf to 583.14844, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 36s 708ms/step - loss: 0.9928 - accuracy: 0.6424 - val_loss: 583.1484 - val_accuracy: 0.3379 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.7756\n",
      "Epoch 2: val_loss improved from 583.14844 to 2.25910, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.6873 - accuracy: 0.7756 - val_loss: 2.2591 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8161\n",
      "Epoch 3: val_loss improved from 2.25910 to 1.30959, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.5393 - accuracy: 0.8161 - val_loss: 1.3096 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.8408\n",
      "Epoch 4: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.5336 - accuracy: 0.8408 - val_loss: 1.3670 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.8758\n",
      "Epoch 5: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.4231 - accuracy: 0.8758 - val_loss: 1.3220 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8634\n",
      "Epoch 6: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.4554 - accuracy: 0.8634 - val_loss: 6.0385 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.8717\n",
      "Epoch 7: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.4189 - accuracy: 0.8717 - val_loss: 1.3365 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.8641\n",
      "Epoch 8: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.4215 - accuracy: 0.8641 - val_loss: 1.6991 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8916\n",
      "Epoch 9: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.3645 - accuracy: 0.8916 - val_loss: 1.3623 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8854\n",
      "Epoch 10: val_loss did not improve from 1.30959\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.3803 - accuracy: 0.8854 - val_loss: 1.3317 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.9025\n",
      "Epoch 11: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.3150 - accuracy: 0.9025 - val_loss: 2.2695 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.8957\n",
      "Epoch 12: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.3209 - accuracy: 0.8957 - val_loss: 1.8340 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9039\n",
      "Epoch 13: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.2929 - accuracy: 0.9039 - val_loss: 1.4471 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9183\n",
      "Epoch 14: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.2576 - accuracy: 0.9183 - val_loss: 1.4011 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.9183\n",
      "Epoch 15: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.2681 - accuracy: 0.9183 - val_loss: 1.3392 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.9149\n",
      "Epoch 16: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.2647 - accuracy: 0.9149 - val_loss: 1.3302 - val_accuracy: 0.3187 - lr: 4.0000e-04\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9128\n",
      "Epoch 17: val_loss did not improve from 1.30959\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.2639 - accuracy: 0.9128 - val_loss: 1.4263 - val_accuracy: 0.3434 - lr: 4.0000e-04\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9204\n",
      "Epoch 18: val_loss did not improve from 1.30959\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.2385 - accuracy: 0.9204 - val_loss: 1.4366 - val_accuracy: 0.3984 - lr: 1.6000e-04\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9327\n",
      "Epoch 19: val_loss improved from 1.30959 to 1.28143, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.2092 - accuracy: 0.9327 - val_loss: 1.2814 - val_accuracy: 0.5137 - lr: 1.6000e-04\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.9314\n",
      "Epoch 20: val_loss improved from 1.28143 to 1.19592, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1938 - accuracy: 0.9314 - val_loss: 1.1959 - val_accuracy: 0.5632 - lr: 1.6000e-04\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9176\n",
      "Epoch 21: val_loss improved from 1.19592 to 1.13249, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 697ms/step - loss: 0.2324 - accuracy: 0.9176 - val_loss: 1.1325 - val_accuracy: 0.6319 - lr: 1.6000e-04\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9334\n",
      "Epoch 22: val_loss improved from 1.13249 to 0.60470, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.2066 - accuracy: 0.9334 - val_loss: 0.6047 - val_accuracy: 0.8104 - lr: 1.6000e-04\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9314\n",
      "Epoch 23: val_loss improved from 0.60470 to 0.49092, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 690ms/step - loss: 0.2082 - accuracy: 0.9314 - val_loss: 0.4909 - val_accuracy: 0.8544 - lr: 1.6000e-04\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.9327\n",
      "Epoch 24: val_loss improved from 0.49092 to 0.44201, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.2061 - accuracy: 0.9327 - val_loss: 0.4420 - val_accuracy: 0.8681 - lr: 1.6000e-04\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9334\n",
      "Epoch 25: val_loss improved from 0.44201 to 0.43417, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1927 - accuracy: 0.9334 - val_loss: 0.4342 - val_accuracy: 0.8599 - lr: 1.6000e-04\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9355\n",
      "Epoch 26: val_loss improved from 0.43417 to 0.35669, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1874 - accuracy: 0.9355 - val_loss: 0.3567 - val_accuracy: 0.8984 - lr: 1.6000e-04\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9327\n",
      "Epoch 27: val_loss improved from 0.35669 to 0.33040, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.2035 - accuracy: 0.9327 - val_loss: 0.3304 - val_accuracy: 0.8929 - lr: 1.6000e-04\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9396\n",
      "Epoch 28: val_loss improved from 0.33040 to 0.30488, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1915 - accuracy: 0.9396 - val_loss: 0.3049 - val_accuracy: 0.9121 - lr: 1.6000e-04\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9300\n",
      "Epoch 29: val_loss improved from 0.30488 to 0.26695, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 692ms/step - loss: 0.1951 - accuracy: 0.9300 - val_loss: 0.2669 - val_accuracy: 0.9286 - lr: 1.6000e-04\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9410\n",
      "Epoch 30: val_loss did not improve from 0.26695\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1795 - accuracy: 0.9410 - val_loss: 0.3052 - val_accuracy: 0.9176 - lr: 1.6000e-04\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9478\n",
      "Epoch 31: val_loss improved from 0.26695 to 0.23720, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 689ms/step - loss: 0.1694 - accuracy: 0.9478 - val_loss: 0.2372 - val_accuracy: 0.9368 - lr: 1.6000e-04\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9403\n",
      "Epoch 32: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.1751 - accuracy: 0.9403 - val_loss: 0.3956 - val_accuracy: 0.8544 - lr: 1.6000e-04\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9465\n",
      "Epoch 33: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1561 - accuracy: 0.9465 - val_loss: 0.2900 - val_accuracy: 0.9148 - lr: 1.6000e-04\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9334\n",
      "Epoch 34: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1835 - accuracy: 0.9334 - val_loss: 0.2851 - val_accuracy: 0.9093 - lr: 1.6000e-04\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9540\n",
      "Epoch 35: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1462 - accuracy: 0.9540 - val_loss: 0.3170 - val_accuracy: 0.9038 - lr: 1.6000e-04\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9389\n",
      "Epoch 36: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1680 - accuracy: 0.9389 - val_loss: 0.3760 - val_accuracy: 0.8736 - lr: 1.6000e-04\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.9499\n",
      "Epoch 37: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1594 - accuracy: 0.9499 - val_loss: 0.2903 - val_accuracy: 0.9203 - lr: 1.6000e-04\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9465\n",
      "Epoch 38: val_loss did not improve from 0.23720\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "46/46 [==============================] - 31s 686ms/step - loss: 0.1533 - accuracy: 0.9465 - val_loss: 0.3159 - val_accuracy: 0.9203 - lr: 1.6000e-04\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9520\n",
      "Epoch 39: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1404 - accuracy: 0.9520 - val_loss: 0.2642 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9506\n",
      "Epoch 40: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.1442 - accuracy: 0.9506 - val_loss: 0.2440 - val_accuracy: 0.9258 - lr: 6.4000e-05\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9547\n",
      "Epoch 41: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 665ms/step - loss: 0.1329 - accuracy: 0.9547 - val_loss: 0.2875 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9533\n",
      "Epoch 42: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.1298 - accuracy: 0.9533 - val_loss: 0.2820 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9643\n",
      "Epoch 43: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1138 - accuracy: 0.9643 - val_loss: 0.2676 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9595\n",
      "Epoch 44: val_loss did not improve from 0.23720\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1361 - accuracy: 0.9595 - val_loss: 0.2770 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9616\n",
      "Epoch 45: val_loss improved from 0.23720 to 0.22086, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 695ms/step - loss: 0.1156 - accuracy: 0.9616 - val_loss: 0.2209 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9561\n",
      "Epoch 46: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1234 - accuracy: 0.9561 - val_loss: 0.2236 - val_accuracy: 0.9423 - lr: 6.4000e-05\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9540\n",
      "Epoch 47: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.1275 - accuracy: 0.9540 - val_loss: 0.2560 - val_accuracy: 0.9368 - lr: 6.4000e-05\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9540\n",
      "Epoch 48: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1348 - accuracy: 0.9540 - val_loss: 0.3054 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9609\n",
      "Epoch 49: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.1309 - accuracy: 0.9609 - val_loss: 0.2216 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9691\n",
      "Epoch 50: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0984 - accuracy: 0.9691 - val_loss: 0.2390 - val_accuracy: 0.9423 - lr: 6.4000e-05\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9602\n",
      "Epoch 51: val_loss did not improve from 0.22086\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.2370 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9581\n",
      "Epoch 52: val_loss improved from 0.22086 to 0.20835, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 694ms/step - loss: 0.1347 - accuracy: 0.9581 - val_loss: 0.2084 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9643\n",
      "Epoch 53: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.1104 - accuracy: 0.9643 - val_loss: 0.2326 - val_accuracy: 0.9451 - lr: 6.4000e-05\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9671\n",
      "Epoch 54: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.1146 - accuracy: 0.9671 - val_loss: 0.2671 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9623\n",
      "Epoch 55: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.1164 - accuracy: 0.9623 - val_loss: 0.2502 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9671\n",
      "Epoch 56: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1042 - accuracy: 0.9671 - val_loss: 0.3127 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9520\n",
      "Epoch 57: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.1393 - accuracy: 0.9520 - val_loss: 0.2170 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9595\n",
      "Epoch 58: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1208 - accuracy: 0.9595 - val_loss: 0.2725 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9554\n",
      "Epoch 59: val_loss did not improve from 0.20835\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1265 - accuracy: 0.9554 - val_loss: 0.2611 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9684\n",
      "Epoch 60: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.1002 - accuracy: 0.9684 - val_loss: 0.2686 - val_accuracy: 0.9313 - lr: 2.5600e-05\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9684\n",
      "Epoch 61: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.1029 - accuracy: 0.9684 - val_loss: 0.2097 - val_accuracy: 0.9341 - lr: 2.5600e-05\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9691\n",
      "Epoch 62: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1001 - accuracy: 0.9691 - val_loss: 0.2449 - val_accuracy: 0.9505 - lr: 2.5600e-05\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9719\n",
      "Epoch 63: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0924 - accuracy: 0.9719 - val_loss: 0.2158 - val_accuracy: 0.9478 - lr: 2.5600e-05\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9616\n",
      "Epoch 64: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0981 - accuracy: 0.9616 - val_loss: 0.2346 - val_accuracy: 0.9396 - lr: 2.5600e-05\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9712\n",
      "Epoch 65: val_loss did not improve from 0.20835\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0859 - accuracy: 0.9712 - val_loss: 0.2552 - val_accuracy: 0.9286 - lr: 2.5600e-05\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9774\n",
      "Epoch 66: val_loss improved from 0.20835 to 0.18437, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.0792 - accuracy: 0.9774 - val_loss: 0.1844 - val_accuracy: 0.9478 - lr: 2.5600e-05\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9725\n",
      "Epoch 67: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0873 - accuracy: 0.9725 - val_loss: 0.2868 - val_accuracy: 0.9286 - lr: 2.5600e-05\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9698\n",
      "Epoch 68: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0954 - accuracy: 0.9698 - val_loss: 0.2501 - val_accuracy: 0.9341 - lr: 2.5600e-05\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9705\n",
      "Epoch 69: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0969 - accuracy: 0.9705 - val_loss: 0.2684 - val_accuracy: 0.9176 - lr: 2.5600e-05\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9746\n",
      "Epoch 70: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0746 - accuracy: 0.9746 - val_loss: 0.2761 - val_accuracy: 0.9258 - lr: 2.5600e-05\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9705\n",
      "Epoch 71: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0921 - accuracy: 0.9705 - val_loss: 0.2752 - val_accuracy: 0.9121 - lr: 2.5600e-05\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9698\n",
      "Epoch 72: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0818 - accuracy: 0.9698 - val_loss: 0.2773 - val_accuracy: 0.9286 - lr: 2.5600e-05\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9746\n",
      "Epoch 73: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0808 - accuracy: 0.9746 - val_loss: 0.2637 - val_accuracy: 0.9176 - lr: 2.5600e-05\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9719\n",
      "Epoch 74: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0780 - accuracy: 0.9719 - val_loss: 0.2662 - val_accuracy: 0.9176 - lr: 1.0240e-05\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9725\n",
      "Epoch 75: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0830 - accuracy: 0.9725 - val_loss: 0.2950 - val_accuracy: 0.9093 - lr: 1.0240e-05\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9753\n",
      "Epoch 76: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0780 - accuracy: 0.9753 - val_loss: 0.2289 - val_accuracy: 0.9341 - lr: 1.0240e-05\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9760\n",
      "Epoch 77: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.2689 - val_accuracy: 0.9368 - lr: 1.0240e-05\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9671\n",
      "Epoch 78: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.2612 - val_accuracy: 0.9231 - lr: 1.0240e-05\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9767\n",
      "Epoch 79: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0739 - accuracy: 0.9767 - val_loss: 0.3061 - val_accuracy: 0.9286 - lr: 1.0240e-05\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9691\n",
      "Epoch 80: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.0861 - accuracy: 0.9691 - val_loss: 0.2453 - val_accuracy: 0.9451 - lr: 1.0240e-05\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9732\n",
      "Epoch 81: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0927 - accuracy: 0.9732 - val_loss: 0.2201 - val_accuracy: 0.9478 - lr: 4.0960e-06\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9684\n",
      "Epoch 82: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0857 - accuracy: 0.9684 - val_loss: 0.2482 - val_accuracy: 0.9451 - lr: 4.0960e-06\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9815\n",
      "Epoch 83: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0664 - accuracy: 0.9815 - val_loss: 0.2671 - val_accuracy: 0.9148 - lr: 4.0960e-06\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9719\n",
      "Epoch 84: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.0895 - accuracy: 0.9719 - val_loss: 0.2152 - val_accuracy: 0.9341 - lr: 4.0960e-06\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9698\n",
      "Epoch 85: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1010 - accuracy: 0.9698 - val_loss: 0.2084 - val_accuracy: 0.9451 - lr: 4.0960e-06\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9732\n",
      "Epoch 86: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0829 - accuracy: 0.9732 - val_loss: 0.2417 - val_accuracy: 0.9478 - lr: 4.0960e-06\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9657\n",
      "Epoch 87: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.0941 - accuracy: 0.9657 - val_loss: 0.2377 - val_accuracy: 0.9368 - lr: 4.0960e-06\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9753\n",
      "Epoch 88: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0669 - accuracy: 0.9753 - val_loss: 0.2511 - val_accuracy: 0.9451 - lr: 1.6384e-06\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9787\n",
      "Epoch 89: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0666 - accuracy: 0.9787 - val_loss: 0.2415 - val_accuracy: 0.9286 - lr: 1.6384e-06\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9725\n",
      "Epoch 90: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0785 - accuracy: 0.9725 - val_loss: 0.2110 - val_accuracy: 0.9451 - lr: 1.6384e-06\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9801\n",
      "Epoch 91: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0725 - accuracy: 0.9801 - val_loss: 0.3329 - val_accuracy: 0.9231 - lr: 1.6384e-06\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9760\n",
      "Epoch 92: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0786 - accuracy: 0.9760 - val_loss: 0.2010 - val_accuracy: 0.9423 - lr: 1.6384e-06\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9753\n",
      "Epoch 93: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.2495 - val_accuracy: 0.9258 - lr: 1.6384e-06\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9725\n",
      "Epoch 94: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.2324 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9767\n",
      "Epoch 95: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0771 - accuracy: 0.9767 - val_loss: 0.2696 - val_accuracy: 0.9258 - lr: 6.5536e-07\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9698\n",
      "Epoch 96: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0842 - accuracy: 0.9698 - val_loss: 0.2640 - val_accuracy: 0.9341 - lr: 6.5536e-07\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9760\n",
      "Epoch 97: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0724 - accuracy: 0.9760 - val_loss: 0.2639 - val_accuracy: 0.9341 - lr: 6.5536e-07\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9698\n",
      "Epoch 98: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0866 - accuracy: 0.9698 - val_loss: 0.2783 - val_accuracy: 0.9176 - lr: 6.5536e-07\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9698\n",
      "Epoch 99: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0924 - accuracy: 0.9698 - val_loss: 0.2543 - val_accuracy: 0.9341 - lr: 6.5536e-07\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9787\n",
      "Epoch 100: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 663ms/step - loss: 0.0681 - accuracy: 0.9787 - val_loss: 0.2035 - val_accuracy: 0.9533 - lr: 6.5536e-07\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9732\n",
      "Epoch 101: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0793 - accuracy: 0.9732 - val_loss: 0.2329 - val_accuracy: 0.9368 - lr: 6.5536e-07\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9739\n",
      "Epoch 102: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0877 - accuracy: 0.9739 - val_loss: 0.2717 - val_accuracy: 0.9313 - lr: 2.6214e-07\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9732\n",
      "Epoch 103: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0818 - accuracy: 0.9732 - val_loss: 0.2532 - val_accuracy: 0.9478 - lr: 2.6214e-07\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9774\n",
      "Epoch 104: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.2391 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9815\n",
      "Epoch 105: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 689ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.2839 - val_accuracy: 0.9396 - lr: 2.6214e-07\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9801\n",
      "Epoch 106: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0695 - accuracy: 0.9801 - val_loss: 0.2687 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9746\n",
      "Epoch 107: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0694 - accuracy: 0.9746 - val_loss: 0.2726 - val_accuracy: 0.9258 - lr: 2.6214e-07\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9774\n",
      "Epoch 108: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 0.2284 - val_accuracy: 0.9396 - lr: 2.6214e-07\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9725\n",
      "Epoch 109: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0864 - accuracy: 0.9725 - val_loss: 0.2465 - val_accuracy: 0.9313 - lr: 1.0486e-07\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9760\n",
      "Epoch 110: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.0681 - accuracy: 0.9760 - val_loss: 0.2531 - val_accuracy: 0.9341 - lr: 1.0486e-07\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9732\n",
      "Epoch 111: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0834 - accuracy: 0.9732 - val_loss: 0.3099 - val_accuracy: 0.9341 - lr: 1.0486e-07\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9801\n",
      "Epoch 112: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0701 - accuracy: 0.9801 - val_loss: 0.2827 - val_accuracy: 0.9396 - lr: 1.0486e-07\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9684\n",
      "Epoch 113: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0867 - accuracy: 0.9684 - val_loss: 0.2488 - val_accuracy: 0.9286 - lr: 1.0486e-07\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9794\n",
      "Epoch 114: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.2470 - val_accuracy: 0.9341 - lr: 1.0486e-07\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9712\n",
      "Epoch 115: val_loss did not improve from 0.18437\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.2616 - val_accuracy: 0.9258 - lr: 1.0486e-07\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9719\n",
      "Epoch 116: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.0866 - accuracy: 0.9719 - val_loss: 0.2332 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9808\n",
      "Epoch 117: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.2093 - val_accuracy: 0.9505 - lr: 1.0000e-07\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9746\n",
      "Epoch 118: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0760 - accuracy: 0.9746 - val_loss: 0.2143 - val_accuracy: 0.9560 - lr: 1.0000e-07\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9767\n",
      "Epoch 119: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 685ms/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.2478 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9760\n",
      "Epoch 120: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 0.2705 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9760\n",
      "Epoch 121: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 0.2619 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9787\n",
      "Epoch 122: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0668 - accuracy: 0.9787 - val_loss: 0.2873 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9774\n",
      "Epoch 123: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0733 - accuracy: 0.9774 - val_loss: 0.3024 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9732\n",
      "Epoch 124: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.2591 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9705\n",
      "Epoch 125: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.2471 - val_accuracy: 0.9451 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9739\n",
      "Epoch 126: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.2671 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9767\n",
      "Epoch 127: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.2781 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9746\n",
      "Epoch 128: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0760 - accuracy: 0.9746 - val_loss: 0.2740 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9787\n",
      "Epoch 129: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 688ms/step - loss: 0.0748 - accuracy: 0.9787 - val_loss: 0.2631 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9671\n",
      "Epoch 130: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0784 - accuracy: 0.9671 - val_loss: 0.2721 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9760\n",
      "Epoch 131: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.0668 - accuracy: 0.9760 - val_loss: 0.2906 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9719\n",
      "Epoch 132: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 0.2434 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9746\n",
      "Epoch 133: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.2529 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9677\n",
      "Epoch 134: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0906 - accuracy: 0.9677 - val_loss: 0.2942 - val_accuracy: 0.9093 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9732\n",
      "Epoch 135: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0815 - accuracy: 0.9732 - val_loss: 0.2299 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9739\n",
      "Epoch 136: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0760 - accuracy: 0.9739 - val_loss: 0.2863 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9815\n",
      "Epoch 137: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 689ms/step - loss: 0.0707 - accuracy: 0.9815 - val_loss: 0.3104 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9725\n",
      "Epoch 138: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0761 - accuracy: 0.9725 - val_loss: 0.3091 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9725\n",
      "Epoch 139: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0745 - accuracy: 0.9725 - val_loss: 0.2588 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9787\n",
      "Epoch 140: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0653 - accuracy: 0.9787 - val_loss: 0.2676 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9746\n",
      "Epoch 141: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.1943 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9801\n",
      "Epoch 142: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0677 - accuracy: 0.9801 - val_loss: 0.2406 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9774\n",
      "Epoch 143: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 0.3245 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9746\n",
      "Epoch 144: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.2958 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9760\n",
      "Epoch 145: val_loss did not improve from 0.18437\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0787 - accuracy: 0.9760 - val_loss: 0.3010 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9835\n",
      "Epoch 146: val_loss improved from 0.18437 to 0.17978, saving model to .\\ResNet50_KFold_ver1_fold4.hdf5\n",
      "46/46 [==============================] - 32s 693ms/step - loss: 0.0548 - accuracy: 0.9835 - val_loss: 0.1798 - val_accuracy: 0.9478 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9767\n",
      "Epoch 147: val_loss did not improve from 0.17978\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0701 - accuracy: 0.9767 - val_loss: 0.2841 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9760\n",
      "Epoch 148: val_loss did not improve from 0.17978\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.2347 - val_accuracy: 0.9505 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9760\n",
      "Epoch 149: val_loss did not improve from 0.17978\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.0826 - accuracy: 0.9760 - val_loss: 0.2924 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9753\n",
      "Epoch 150: val_loss did not improve from 0.17978\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0781 - accuracy: 0.9753 - val_loss: 0.2596 - val_accuracy: 0.9148 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold: 5\n",
      "Found 1457 validated image filenames.\n",
      "Found 364 validated image filenames.\n",
      "Found 1821 validated image filenames.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          262272      ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           8256        ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 4)            260         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,858,500\n",
      "Trainable params: 23,805,380\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.8639 - accuracy: 0.7056\n",
      "Epoch 1: val_loss improved from inf to 1967.83350, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 36s 722ms/step - loss: 0.8639 - accuracy: 0.7056 - val_loss: 1967.8335 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.8037\n",
      "Epoch 2: val_loss improved from 1967.83350 to 1.36396, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.6111 - accuracy: 0.8037 - val_loss: 1.3640 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8339\n",
      "Epoch 3: val_loss did not improve from 1.36396\n",
      "46/46 [==============================] - 31s 663ms/step - loss: 0.5384 - accuracy: 0.8339 - val_loss: 2.2444 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.8655\n",
      "Epoch 4: val_loss did not improve from 1.36396\n",
      "46/46 [==============================] - 30s 656ms/step - loss: 0.4502 - accuracy: 0.8655 - val_loss: 1.4697 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8614\n",
      "Epoch 5: val_loss did not improve from 1.36396\n",
      "46/46 [==============================] - 30s 657ms/step - loss: 0.4304 - accuracy: 0.8614 - val_loss: 1.5499 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8744\n",
      "Epoch 6: val_loss did not improve from 1.36396\n",
      "46/46 [==============================] - 30s 650ms/step - loss: 0.4005 - accuracy: 0.8744 - val_loss: 1.7034 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.8874\n",
      "Epoch 7: val_loss did not improve from 1.36396\n",
      "46/46 [==============================] - 30s 652ms/step - loss: 0.3630 - accuracy: 0.8874 - val_loss: 1.5379 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8868\n",
      "Epoch 8: val_loss improved from 1.36396 to 1.35594, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.3802 - accuracy: 0.8868 - val_loss: 1.3559 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8936\n",
      "Epoch 9: val_loss improved from 1.35594 to 1.34585, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.3492 - accuracy: 0.8936 - val_loss: 1.3459 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8806\n",
      "Epoch 10: val_loss improved from 1.34585 to 1.34321, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.3977 - accuracy: 0.8806 - val_loss: 1.3432 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8868\n",
      "Epoch 11: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 662ms/step - loss: 0.3608 - accuracy: 0.8868 - val_loss: 1.4695 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8909\n",
      "Epoch 12: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.3403 - accuracy: 0.8909 - val_loss: 2.7501 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.8792\n",
      "Epoch 13: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 30s 659ms/step - loss: 0.3757 - accuracy: 0.8792 - val_loss: 6.7554 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8922\n",
      "Epoch 14: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 659ms/step - loss: 0.3438 - accuracy: 0.8922 - val_loss: 2.0407 - val_accuracy: 0.3049 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8868\n",
      "Epoch 15: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 661ms/step - loss: 0.3286 - accuracy: 0.8868 - val_loss: 1.6411 - val_accuracy: 0.3104 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.9032\n",
      "Epoch 16: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.3168 - accuracy: 0.9032 - val_loss: 3.0416 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.8881\n",
      "Epoch 17: val_loss did not improve from 1.34321\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.3376 - accuracy: 0.8881 - val_loss: 1.7121 - val_accuracy: 0.3022 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9012\n",
      "Epoch 18: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 663ms/step - loss: 0.2849 - accuracy: 0.9012 - val_loss: 2.1996 - val_accuracy: 0.3819 - lr: 4.0000e-04\n",
      "Epoch 19/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9286\n",
      "Epoch 19: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 30s 656ms/step - loss: 0.2318 - accuracy: 0.9286 - val_loss: 1.8187 - val_accuracy: 0.3544 - lr: 4.0000e-04\n",
      "Epoch 20/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9279\n",
      "Epoch 20: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 661ms/step - loss: 0.2146 - accuracy: 0.9279 - val_loss: 2.1356 - val_accuracy: 0.3901 - lr: 4.0000e-04\n",
      "Epoch 21/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9245\n",
      "Epoch 21: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 662ms/step - loss: 0.2398 - accuracy: 0.9245 - val_loss: 1.6903 - val_accuracy: 0.5055 - lr: 4.0000e-04\n",
      "Epoch 22/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9355\n",
      "Epoch 22: val_loss did not improve from 1.34321\n",
      "46/46 [==============================] - 31s 661ms/step - loss: 0.2132 - accuracy: 0.9355 - val_loss: 1.7971 - val_accuracy: 0.5604 - lr: 4.0000e-04\n",
      "Epoch 23/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9197\n",
      "Epoch 23: val_loss improved from 1.34321 to 1.05966, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.2148 - accuracy: 0.9197 - val_loss: 1.0597 - val_accuracy: 0.7390 - lr: 4.0000e-04\n",
      "Epoch 24/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9293\n",
      "Epoch 24: val_loss improved from 1.05966 to 0.52020, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.2264 - accuracy: 0.9293 - val_loss: 0.5202 - val_accuracy: 0.8077 - lr: 4.0000e-04\n",
      "Epoch 25/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9321\n",
      "Epoch 25: val_loss improved from 0.52020 to 0.41662, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 688ms/step - loss: 0.2084 - accuracy: 0.9321 - val_loss: 0.4166 - val_accuracy: 0.8874 - lr: 4.0000e-04\n",
      "Epoch 26/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9190\n",
      "Epoch 26: val_loss did not improve from 0.41662\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.2308 - accuracy: 0.9190 - val_loss: 0.5581 - val_accuracy: 0.8379 - lr: 4.0000e-04\n",
      "Epoch 27/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9389\n",
      "Epoch 27: val_loss did not improve from 0.41662\n",
      "46/46 [==============================] - 30s 654ms/step - loss: 0.1962 - accuracy: 0.9389 - val_loss: 0.4648 - val_accuracy: 0.8709 - lr: 4.0000e-04\n",
      "Epoch 28/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9307\n",
      "Epoch 28: val_loss improved from 0.41662 to 0.31821, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.2197 - accuracy: 0.9307 - val_loss: 0.3182 - val_accuracy: 0.9148 - lr: 4.0000e-04\n",
      "Epoch 29/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9437\n",
      "Epoch 29: val_loss did not improve from 0.31821\n",
      "46/46 [==============================] - 30s 655ms/step - loss: 0.1884 - accuracy: 0.9437 - val_loss: 0.4013 - val_accuracy: 0.8819 - lr: 4.0000e-04\n",
      "Epoch 30/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9410\n",
      "Epoch 30: val_loss improved from 0.31821 to 0.25589, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.1946 - accuracy: 0.9410 - val_loss: 0.2559 - val_accuracy: 0.9148 - lr: 4.0000e-04\n",
      "Epoch 31/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9382\n",
      "Epoch 31: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.1919 - accuracy: 0.9382 - val_loss: 0.3623 - val_accuracy: 0.9313 - lr: 4.0000e-04\n",
      "Epoch 32/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9389\n",
      "Epoch 32: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 31s 665ms/step - loss: 0.1928 - accuracy: 0.9389 - val_loss: 0.4282 - val_accuracy: 0.8901 - lr: 4.0000e-04\n",
      "Epoch 33/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9437\n",
      "Epoch 33: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 31s 665ms/step - loss: 0.1804 - accuracy: 0.9437 - val_loss: 0.3693 - val_accuracy: 0.8819 - lr: 4.0000e-04\n",
      "Epoch 34/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9341\n",
      "Epoch 34: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.1889 - accuracy: 0.9341 - val_loss: 0.2777 - val_accuracy: 0.9066 - lr: 4.0000e-04\n",
      "Epoch 35/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9382\n",
      "Epoch 35: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 31s 662ms/step - loss: 0.1844 - accuracy: 0.9382 - val_loss: 0.3973 - val_accuracy: 0.8736 - lr: 4.0000e-04\n",
      "Epoch 36/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9355\n",
      "Epoch 36: val_loss did not improve from 0.25589\n",
      "46/46 [==============================] - 30s 651ms/step - loss: 0.1985 - accuracy: 0.9355 - val_loss: 0.3203 - val_accuracy: 0.9148 - lr: 4.0000e-04\n",
      "Epoch 37/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9369\n",
      "Epoch 37: val_loss did not improve from 0.25589\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "46/46 [==============================] - 30s 657ms/step - loss: 0.1794 - accuracy: 0.9369 - val_loss: 0.3088 - val_accuracy: 0.9038 - lr: 4.0000e-04\n",
      "Epoch 38/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9526\n",
      "Epoch 38: val_loss improved from 0.25589 to 0.25330, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1536 - accuracy: 0.9526 - val_loss: 0.2533 - val_accuracy: 0.9121 - lr: 1.6000e-04\n",
      "Epoch 39/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9478\n",
      "Epoch 39: val_loss improved from 0.25330 to 0.24827, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1547 - accuracy: 0.9478 - val_loss: 0.2483 - val_accuracy: 0.9203 - lr: 1.6000e-04\n",
      "Epoch 40/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9451\n",
      "Epoch 40: val_loss improved from 0.24827 to 0.23617, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1659 - accuracy: 0.9451 - val_loss: 0.2362 - val_accuracy: 0.9560 - lr: 1.6000e-04\n",
      "Epoch 41/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9554\n",
      "Epoch 41: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.1440 - accuracy: 0.9554 - val_loss: 0.2712 - val_accuracy: 0.9313 - lr: 1.6000e-04\n",
      "Epoch 42/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9602\n",
      "Epoch 42: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 31s 662ms/step - loss: 0.1263 - accuracy: 0.9602 - val_loss: 0.2616 - val_accuracy: 0.9176 - lr: 1.6000e-04\n",
      "Epoch 43/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9499\n",
      "Epoch 43: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 30s 656ms/step - loss: 0.1495 - accuracy: 0.9499 - val_loss: 0.3085 - val_accuracy: 0.9286 - lr: 1.6000e-04\n",
      "Epoch 44/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9616\n",
      "Epoch 44: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 30s 656ms/step - loss: 0.1180 - accuracy: 0.9616 - val_loss: 0.2869 - val_accuracy: 0.9148 - lr: 1.6000e-04\n",
      "Epoch 45/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9492\n",
      "Epoch 45: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 30s 653ms/step - loss: 0.1377 - accuracy: 0.9492 - val_loss: 0.3418 - val_accuracy: 0.9121 - lr: 1.6000e-04\n",
      "Epoch 46/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9609\n",
      "Epoch 46: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 31s 660ms/step - loss: 0.1214 - accuracy: 0.9609 - val_loss: 0.2753 - val_accuracy: 0.9258 - lr: 1.6000e-04\n",
      "Epoch 47/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9465\n",
      "Epoch 47: val_loss did not improve from 0.23617\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "46/46 [==============================] - 31s 663ms/step - loss: 0.1446 - accuracy: 0.9465 - val_loss: 0.2911 - val_accuracy: 0.9066 - lr: 1.6000e-04\n",
      "Epoch 48/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9588\n",
      "Epoch 48: val_loss did not improve from 0.23617\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.1226 - accuracy: 0.9588 - val_loss: 0.2790 - val_accuracy: 0.9066 - lr: 6.4000e-05\n",
      "Epoch 49/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9588\n",
      "Epoch 49: val_loss improved from 0.23617 to 0.20336, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.1209 - accuracy: 0.9588 - val_loss: 0.2034 - val_accuracy: 0.9423 - lr: 6.4000e-05\n",
      "Epoch 50/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9650\n",
      "Epoch 50: val_loss did not improve from 0.20336\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.1103 - accuracy: 0.9650 - val_loss: 0.2413 - val_accuracy: 0.9286 - lr: 6.4000e-05\n",
      "Epoch 51/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9636\n",
      "Epoch 51: val_loss did not improve from 0.20336\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.2469 - val_accuracy: 0.9313 - lr: 6.4000e-05\n",
      "Epoch 52/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9629\n",
      "Epoch 52: val_loss did not improve from 0.20336\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1171 - accuracy: 0.9629 - val_loss: 0.2942 - val_accuracy: 0.9203 - lr: 6.4000e-05\n",
      "Epoch 53/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9725\n",
      "Epoch 53: val_loss did not improve from 0.20336\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0993 - accuracy: 0.9725 - val_loss: 0.2618 - val_accuracy: 0.9258 - lr: 6.4000e-05\n",
      "Epoch 54/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9684\n",
      "Epoch 54: val_loss did not improve from 0.20336\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1016 - accuracy: 0.9684 - val_loss: 0.2552 - val_accuracy: 0.9423 - lr: 6.4000e-05\n",
      "Epoch 55/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9712\n",
      "Epoch 55: val_loss improved from 0.20336 to 0.19876, saving model to .\\ResNet50_KFold_ver1_fold5.hdf5\n",
      "46/46 [==============================] - 32s 699ms/step - loss: 0.1023 - accuracy: 0.9712 - val_loss: 0.1988 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 56/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9636\n",
      "Epoch 56: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.1139 - accuracy: 0.9636 - val_loss: 0.2761 - val_accuracy: 0.9176 - lr: 6.4000e-05\n",
      "Epoch 57/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9588\n",
      "Epoch 57: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.1151 - accuracy: 0.9588 - val_loss: 0.3183 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 58/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9691\n",
      "Epoch 58: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.1011 - accuracy: 0.9691 - val_loss: 0.2597 - val_accuracy: 0.9396 - lr: 6.4000e-05\n",
      "Epoch 59/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9705\n",
      "Epoch 59: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0934 - accuracy: 0.9705 - val_loss: 0.2166 - val_accuracy: 0.9368 - lr: 6.4000e-05\n",
      "Epoch 60/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9677\n",
      "Epoch 60: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0924 - accuracy: 0.9677 - val_loss: 0.3211 - val_accuracy: 0.9148 - lr: 6.4000e-05\n",
      "Epoch 61/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9664\n",
      "Epoch 61: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.1124 - accuracy: 0.9664 - val_loss: 0.3037 - val_accuracy: 0.9038 - lr: 6.4000e-05\n",
      "Epoch 62/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9643\n",
      "Epoch 62: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0964 - accuracy: 0.9643 - val_loss: 0.2617 - val_accuracy: 0.9341 - lr: 6.4000e-05\n",
      "Epoch 63/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9664\n",
      "Epoch 63: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1017 - accuracy: 0.9664 - val_loss: 0.2874 - val_accuracy: 0.9396 - lr: 2.5600e-05\n",
      "Epoch 64/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9698\n",
      "Epoch 64: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0859 - accuracy: 0.9698 - val_loss: 0.2876 - val_accuracy: 0.9231 - lr: 2.5600e-05\n",
      "Epoch 65/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9698\n",
      "Epoch 65: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0870 - accuracy: 0.9698 - val_loss: 0.2225 - val_accuracy: 0.9533 - lr: 2.5600e-05\n",
      "Epoch 66/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9780\n",
      "Epoch 66: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0700 - accuracy: 0.9780 - val_loss: 0.3031 - val_accuracy: 0.9176 - lr: 2.5600e-05\n",
      "Epoch 67/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9746\n",
      "Epoch 67: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0765 - accuracy: 0.9746 - val_loss: 0.2865 - val_accuracy: 0.9451 - lr: 2.5600e-05\n",
      "Epoch 68/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9677\n",
      "Epoch 68: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 0.2343 - val_accuracy: 0.9423 - lr: 2.5600e-05\n",
      "Epoch 69/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9671\n",
      "Epoch 69: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.1020 - accuracy: 0.9671 - val_loss: 0.2737 - val_accuracy: 0.9231 - lr: 2.5600e-05\n",
      "Epoch 70/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9705\n",
      "Epoch 70: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0841 - accuracy: 0.9705 - val_loss: 0.2474 - val_accuracy: 0.9313 - lr: 1.0240e-05\n",
      "Epoch 71/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9684\n",
      "Epoch 71: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0915 - accuracy: 0.9684 - val_loss: 0.3007 - val_accuracy: 0.9121 - lr: 1.0240e-05\n",
      "Epoch 72/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9712\n",
      "Epoch 72: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0839 - accuracy: 0.9712 - val_loss: 0.2305 - val_accuracy: 0.9396 - lr: 1.0240e-05\n",
      "Epoch 73/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9753\n",
      "Epoch 73: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0780 - accuracy: 0.9753 - val_loss: 0.2390 - val_accuracy: 0.9341 - lr: 1.0240e-05\n",
      "Epoch 74/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9787\n",
      "Epoch 74: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 0.2777 - val_accuracy: 0.9231 - lr: 1.0240e-05\n",
      "Epoch 75/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9712\n",
      "Epoch 75: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 47s 1s/step - loss: 0.0919 - accuracy: 0.9712 - val_loss: 0.2573 - val_accuracy: 0.9396 - lr: 1.0240e-05\n",
      "Epoch 76/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9767\n",
      "Epoch 76: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "46/46 [==============================] - 38s 823ms/step - loss: 0.0814 - accuracy: 0.9767 - val_loss: 0.2073 - val_accuracy: 0.9423 - lr: 1.0240e-05\n",
      "Epoch 77/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9732\n",
      "Epoch 77: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 665ms/step - loss: 0.0854 - accuracy: 0.9732 - val_loss: 0.2949 - val_accuracy: 0.9176 - lr: 4.0960e-06\n",
      "Epoch 78/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9767\n",
      "Epoch 78: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 666ms/step - loss: 0.0686 - accuracy: 0.9767 - val_loss: 0.2339 - val_accuracy: 0.9368 - lr: 4.0960e-06\n",
      "Epoch 79/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9725\n",
      "Epoch 79: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 0.2657 - val_accuracy: 0.9231 - lr: 4.0960e-06\n",
      "Epoch 80/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9801\n",
      "Epoch 80: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0720 - accuracy: 0.9801 - val_loss: 0.3339 - val_accuracy: 0.9231 - lr: 4.0960e-06\n",
      "Epoch 81/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9760\n",
      "Epoch 81: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0859 - accuracy: 0.9760 - val_loss: 0.2864 - val_accuracy: 0.9341 - lr: 4.0960e-06\n",
      "Epoch 82/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9739\n",
      "Epoch 82: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0838 - accuracy: 0.9739 - val_loss: 0.3048 - val_accuracy: 0.9231 - lr: 4.0960e-06\n",
      "Epoch 83/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9739\n",
      "Epoch 83: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "46/46 [==============================] - 31s 664ms/step - loss: 0.0828 - accuracy: 0.9739 - val_loss: 0.3122 - val_accuracy: 0.9121 - lr: 4.0960e-06\n",
      "Epoch 84/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9705\n",
      "Epoch 84: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0853 - accuracy: 0.9705 - val_loss: 0.2952 - val_accuracy: 0.9313 - lr: 1.6384e-06\n",
      "Epoch 85/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9725\n",
      "Epoch 85: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.2613 - val_accuracy: 0.9286 - lr: 1.6384e-06\n",
      "Epoch 86/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9739\n",
      "Epoch 86: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.2728 - val_accuracy: 0.9286 - lr: 1.6384e-06\n",
      "Epoch 87/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9725\n",
      "Epoch 87: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0864 - accuracy: 0.9725 - val_loss: 0.2751 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 88/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9725\n",
      "Epoch 88: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0944 - accuracy: 0.9725 - val_loss: 0.2358 - val_accuracy: 0.9341 - lr: 1.6384e-06\n",
      "Epoch 89/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9684\n",
      "Epoch 89: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.1003 - accuracy: 0.9684 - val_loss: 0.2849 - val_accuracy: 0.9231 - lr: 1.6384e-06\n",
      "Epoch 90/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9739\n",
      "Epoch 90: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 0.2777 - val_accuracy: 0.9368 - lr: 1.6384e-06\n",
      "Epoch 91/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9725\n",
      "Epoch 91: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.2485 - val_accuracy: 0.9286 - lr: 6.5536e-07\n",
      "Epoch 92/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9794\n",
      "Epoch 92: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0728 - accuracy: 0.9794 - val_loss: 0.2735 - val_accuracy: 0.9313 - lr: 6.5536e-07\n",
      "Epoch 93/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9725\n",
      "Epoch 93: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0879 - accuracy: 0.9725 - val_loss: 0.3069 - val_accuracy: 0.9258 - lr: 6.5536e-07\n",
      "Epoch 94/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9760\n",
      "Epoch 94: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0782 - accuracy: 0.9760 - val_loss: 0.2326 - val_accuracy: 0.9396 - lr: 6.5536e-07\n",
      "Epoch 95/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9671\n",
      "Epoch 95: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0935 - accuracy: 0.9671 - val_loss: 0.2739 - val_accuracy: 0.9368 - lr: 6.5536e-07\n",
      "Epoch 96/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9815\n",
      "Epoch 96: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0685 - accuracy: 0.9815 - val_loss: 0.2505 - val_accuracy: 0.9423 - lr: 6.5536e-07\n",
      "Epoch 97/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9746\n",
      "Epoch 97: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0888 - accuracy: 0.9746 - val_loss: 0.3185 - val_accuracy: 0.9258 - lr: 6.5536e-07\n",
      "Epoch 98/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9760\n",
      "Epoch 98: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0889 - accuracy: 0.9760 - val_loss: 0.2617 - val_accuracy: 0.9258 - lr: 2.6214e-07\n",
      "Epoch 99/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9760\n",
      "Epoch 99: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0780 - accuracy: 0.9760 - val_loss: 0.2899 - val_accuracy: 0.9368 - lr: 2.6214e-07\n",
      "Epoch 100/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9609\n",
      "Epoch 100: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.1097 - accuracy: 0.9609 - val_loss: 0.2576 - val_accuracy: 0.9313 - lr: 2.6214e-07\n",
      "Epoch 101/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9780\n",
      "Epoch 101: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0687 - accuracy: 0.9780 - val_loss: 0.2340 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 102/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9774\n",
      "Epoch 102: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 0.3399 - val_accuracy: 0.9121 - lr: 2.6214e-07\n",
      "Epoch 103/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9677\n",
      "Epoch 103: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0841 - accuracy: 0.9677 - val_loss: 0.2513 - val_accuracy: 0.9341 - lr: 2.6214e-07\n",
      "Epoch 104/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9760\n",
      "Epoch 104: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0718 - accuracy: 0.9760 - val_loss: 0.3182 - val_accuracy: 0.9286 - lr: 2.6214e-07\n",
      "Epoch 105/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9746\n",
      "Epoch 105: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 668ms/step - loss: 0.0824 - accuracy: 0.9746 - val_loss: 0.2787 - val_accuracy: 0.9313 - lr: 1.0486e-07\n",
      "Epoch 106/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9767\n",
      "Epoch 106: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0777 - accuracy: 0.9767 - val_loss: 0.3025 - val_accuracy: 0.9368 - lr: 1.0486e-07\n",
      "Epoch 107/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9698\n",
      "Epoch 107: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 0.3138 - val_accuracy: 0.9231 - lr: 1.0486e-07\n",
      "Epoch 108/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9698\n",
      "Epoch 108: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0847 - accuracy: 0.9698 - val_loss: 0.2547 - val_accuracy: 0.9396 - lr: 1.0486e-07\n",
      "Epoch 109/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9671\n",
      "Epoch 109: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0916 - accuracy: 0.9671 - val_loss: 0.3150 - val_accuracy: 0.9121 - lr: 1.0486e-07\n",
      "Epoch 110/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9767\n",
      "Epoch 110: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0748 - accuracy: 0.9767 - val_loss: 0.2890 - val_accuracy: 0.9313 - lr: 1.0486e-07\n",
      "Epoch 111/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9732\n",
      "Epoch 111: val_loss did not improve from 0.19876\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0855 - accuracy: 0.9732 - val_loss: 0.3230 - val_accuracy: 0.9176 - lr: 1.0486e-07\n",
      "Epoch 112/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9684\n",
      "Epoch 112: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0945 - accuracy: 0.9684 - val_loss: 0.2744 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 113/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9705\n",
      "Epoch 113: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0848 - accuracy: 0.9705 - val_loss: 0.2714 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 114/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9739\n",
      "Epoch 114: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 0.3116 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 115/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9767\n",
      "Epoch 115: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0774 - accuracy: 0.9767 - val_loss: 0.2632 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 116/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9801\n",
      "Epoch 116: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 686ms/step - loss: 0.0637 - accuracy: 0.9801 - val_loss: 0.2991 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 117/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9719\n",
      "Epoch 117: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 684ms/step - loss: 0.0912 - accuracy: 0.9719 - val_loss: 0.2848 - val_accuracy: 0.9148 - lr: 1.0000e-07\n",
      "Epoch 118/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9767\n",
      "Epoch 118: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0745 - accuracy: 0.9767 - val_loss: 0.2705 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 119/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9828\n",
      "Epoch 119: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 673ms/step - loss: 0.0652 - accuracy: 0.9828 - val_loss: 0.3596 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 120/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9719\n",
      "Epoch 120: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 0.3012 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 121/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9684\n",
      "Epoch 121: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0853 - accuracy: 0.9684 - val_loss: 0.2391 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 122/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9739\n",
      "Epoch 122: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0909 - accuracy: 0.9739 - val_loss: 0.2521 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 123/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9753\n",
      "Epoch 123: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0802 - accuracy: 0.9753 - val_loss: 0.2936 - val_accuracy: 0.9121 - lr: 1.0000e-07\n",
      "Epoch 124/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9746\n",
      "Epoch 124: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: 0.3037 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 125/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9746\n",
      "Epoch 125: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.0747 - accuracy: 0.9746 - val_loss: 0.2609 - val_accuracy: 0.9203 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9835\n",
      "Epoch 126: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0636 - accuracy: 0.9835 - val_loss: 0.2686 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9739\n",
      "Epoch 127: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0754 - accuracy: 0.9739 - val_loss: 0.2426 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9753\n",
      "Epoch 128: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 667ms/step - loss: 0.0707 - accuracy: 0.9753 - val_loss: 0.2916 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9767\n",
      "Epoch 129: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 670ms/step - loss: 0.0831 - accuracy: 0.9767 - val_loss: 0.3346 - val_accuracy: 0.9121 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9698\n",
      "Epoch 130: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0855 - accuracy: 0.9698 - val_loss: 0.2749 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9801\n",
      "Epoch 131: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 681ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.3035 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9794\n",
      "Epoch 132: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0641 - accuracy: 0.9794 - val_loss: 0.2609 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9705\n",
      "Epoch 133: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 679ms/step - loss: 0.0782 - accuracy: 0.9705 - val_loss: 0.3245 - val_accuracy: 0.9176 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9712\n",
      "Epoch 134: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0845 - accuracy: 0.9712 - val_loss: 0.2301 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9760\n",
      "Epoch 135: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 677ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.3039 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9774\n",
      "Epoch 136: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 671ms/step - loss: 0.0875 - accuracy: 0.9774 - val_loss: 0.3186 - val_accuracy: 0.9286 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9760\n",
      "Epoch 137: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 682ms/step - loss: 0.0854 - accuracy: 0.9760 - val_loss: 0.3365 - val_accuracy: 0.9176 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9732\n",
      "Epoch 138: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 674ms/step - loss: 0.0840 - accuracy: 0.9732 - val_loss: 0.2345 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9739\n",
      "Epoch 139: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.0756 - accuracy: 0.9739 - val_loss: 0.2587 - val_accuracy: 0.9313 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9671\n",
      "Epoch 140: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 685ms/step - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.2265 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9760\n",
      "Epoch 141: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0720 - accuracy: 0.9760 - val_loss: 0.2942 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9698\n",
      "Epoch 142: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 676ms/step - loss: 0.0984 - accuracy: 0.9698 - val_loss: 0.3001 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9698\n",
      "Epoch 143: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 678ms/step - loss: 0.0944 - accuracy: 0.9698 - val_loss: 0.3501 - val_accuracy: 0.9093 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9767\n",
      "Epoch 144: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 669ms/step - loss: 0.0731 - accuracy: 0.9767 - val_loss: 0.2839 - val_accuracy: 0.9258 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9835\n",
      "Epoch 145: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0651 - accuracy: 0.9835 - val_loss: 0.2527 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9705\n",
      "Epoch 146: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 687ms/step - loss: 0.0866 - accuracy: 0.9705 - val_loss: 0.2661 - val_accuracy: 0.9368 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9808\n",
      "Epoch 147: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 32s 683ms/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 0.2943 - val_accuracy: 0.9231 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9753\n",
      "Epoch 148: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.2242 - val_accuracy: 0.9396 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9705\n",
      "Epoch 149: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 675ms/step - loss: 0.0854 - accuracy: 0.9705 - val_loss: 0.3042 - val_accuracy: 0.9341 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9705\n",
      "Epoch 150: val_loss did not improve from 0.19876\n",
      "46/46 [==============================] - 31s 672ms/step - loss: 0.0897 - accuracy: 0.9705 - val_loss: 0.2534 - val_accuracy: 0.9286 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 55s 962ms/step\n"
     ]
    }
   ],
   "source": [
    "name = os.listdir('./')[0].split('.')[0]\n",
    "print(name)\n",
    "\n",
    "path = '../data/plant-pathology-2020-fgvc7/'\n",
    "\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "train['image_id'] = train['image_id'] + '.jpg'\n",
    "test['image_id'] = test['image_id'] + '.jpg'\n",
    "\n",
    "img = []\n",
    "filename = train.image_id\n",
    "for file in filename:\n",
    "    image = cv2.imread(path + \"images/\" + file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    res = cv2.resize(image, (256, 256))\n",
    "    img.append(res)\n",
    "img = np.array(img)\n",
    "\n",
    "train_labels = np.float32(train.loc[:, 'healthy':'scab'].values)\n",
    "\n",
    "# Splitting the data into train and validation sets using K-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "for train_indices, val_indices in kfold.split(train):\n",
    "    print(f\"Training on fold: {fold}\")\n",
    "    train_fold = train.iloc[train_indices]\n",
    "    val_fold = train.iloc[val_indices]\n",
    "\n",
    "    train_datagen = \\\n",
    "    ImageDataGenerator( horizontal_flip=True,\n",
    "                        vertical_flip=True,\n",
    "                        rotation_range=45,\n",
    "                        width_shift_range=0.45,\n",
    "                        height_shift_range=0.45,\n",
    "                        zoom_range=.2,\n",
    "                        fill_mode='nearest',\n",
    "                        rescale=1 / 255,\n",
    "                        brightness_range=[0.5, 1.5])\n",
    "\n",
    "    train_generator = \\\n",
    "    train_datagen.flow_from_dataframe(  train_fold, \n",
    "                                        directory=path + 'images/',\n",
    "                                        target_size=(256, 256),\n",
    "                                        x_col=\"image_id\",\n",
    "                                        y_col=['healthy', 'multiple_diseases', 'rust', 'scab'],\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=32)\n",
    "\n",
    "    val_generator = \\\n",
    "    train_datagen.flow_from_dataframe(  val_fold, \n",
    "                                        directory=path + 'images/',\n",
    "                                        target_size=(256, 256),\n",
    "                                        x_col=\"image_id\",\n",
    "                                        y_col=['healthy', 'multiple_diseases', 'rust', 'scab'],\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=32)\n",
    "\n",
    "\n",
    "    model_finetuned = ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "    x = model_finetuned.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    predictions = Dense(4, activation=\"softmax\")(x)\n",
    "    model_finetuned = Model(inputs=model_finetuned.input, outputs=predictions)\n",
    "    model_finetuned.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_finetuned.summary()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", verbose=1, patience=15)\n",
    "\n",
    "    modelcheckpointer = \\\n",
    "    ModelCheckpoint(f'./{name}_fold{fold}.hdf5', \n",
    "                    monitor='val_loss', \\\n",
    "                    mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "    history = model_finetuned.fit(train_generator, epochs=150, batch_size=8, \n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_batch_size=8, verbose=1, \n",
    "                                  shuffle=True,\n",
    "                                  callbacks=[modelcheckpointer, ReduceLROnPlateau(monitor='val_loss', factor=0.4,\n",
    "                                                                                  patience=7, min_lr=0.0000001,\n",
    "                                                                                  verbose=1)])\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    y_vloss = history.history['val_loss']\n",
    "    y_loss = history.history['loss']\n",
    "    y_acc = history.history['accuracy']\n",
    "    y_vacc = history.history['val_accuracy']\n",
    "    best_val_accuracy = np.array(y_vacc).max()\n",
    "    x_len = np.arange(len(y_loss))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x_len, y_vloss, marker='.', c='red', label='val_loss')\n",
    "    plt.plot(x_len, y_loss, marker='.', c='blue', label='train_loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_len, y_vacc, marker='.', c='orange', label='val_accuracy')\n",
    "    plt.plot(x_len, y_acc, marker='.', c='green', label='train_accuracy')\n",
    "    plt.title(f'best train_accuracy : {best_val_accuracy}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.savefig(f'../그래프/{name}_fold{fold}_{best_val_accuracy}.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "\n",
    "test_generator = \\\n",
    "train_datagen.flow_from_dataframe(test, \n",
    "                                directory=path + 'images/',\n",
    "                                target_size=(256, 256),\n",
    "                                x_col=\"image_id\",\n",
    "                                y_col=None,\n",
    "                                class_mode=None,\n",
    "                                shuffle=False,\n",
    "                                batch_size=32)\n",
    "\n",
    "\n",
    "SUB_PATH = path + \"sample_submission.csv\"\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "\n",
    "# Combine predictions from all folds\n",
    "probs_RESNET = np.zeros((test.shape[0], 4))\n",
    "fold = 5\n",
    "for i in range(1, fold + 1):\n",
    "    model_finetuned.load_weights(f'./{name}_fold{i}.hdf5')\n",
    "    fold_probs = model_finetuned.predict(test_generator, verbose=1)\n",
    "    probs_RESNET += fold_probs\n",
    "probs_RESNET /= fold\n",
    "\n",
    "sub.loc[:, 'healthy':] = probs_RESNET\n",
    "sub.to_csv(f'./{name}_submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minsub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
